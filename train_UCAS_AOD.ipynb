{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "train_UCAS_AOD.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOskAAoOo7uJuxOTgXEN4v3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmoghadam11/ReDet/blob/master/train_UCAS_AOD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my_dkIJk2Zxp"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_0jJz2z2vSD",
        "outputId": "daff1381-b79c-46e3-d3c0-e1e3b63cd781"
      },
      "source": [
        "#باشد tesla t4 باید\n",
        "#اگر نبود در بخش ران تایم - منیج سشن - ترمینت شود و از اول کار شروع شود\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Sep 10 13:25:32 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   72C    P8    32W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yw669oToe48J"
      },
      "source": [
        "# pytorch نصب"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wP7Oo2gzpf3s"
      },
      "source": [
        "# !pip install torch=1.3.1 torchvision cudatoolkit=10.0 \n",
        "!pip install torch==1.1.0 torchvision==0.3.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zu855d3Fp8mg"
      },
      "source": [
        "# نصب ریپازیتوری"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xW88lC3Aqs9S"
      },
      "source": [
        "# !git clone https://github.com/dingjiansw101/AerialDetection.git\n",
        "# !git clone https://github.com/csuhan/ReDet.git\n",
        "!git clone https://github.com/mmoghadam11/ReDet.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnNs-A6grLzS"
      },
      "source": [
        "%cd /content/ReDet\n",
        "! chmod +rx ./compile.sh\n",
        "!./compile.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULAHXBESugF4"
      },
      "source": [
        "!python setup.py develop\n",
        "# !pip install -e ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYurbclbqDrY"
      },
      "source": [
        "# نصب DOTA_devkit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmL2sGYEupcz"
      },
      "source": [
        "! apt-get install swig\n",
        "%cd /content/ReDet/DOTA_devkit\n",
        "!swig -c++ -python polyiou.i\n",
        "!python setup.py build_ext --inplace"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wklxzgvdv4f7"
      },
      "source": [
        "# حال وقت آن است که تصاویری با اندازه ۱۰۲۴*۱۰۲۴ بسازیم و حجم نهیی آن بیش از ۳۵ گیگ خواهد بود"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "On2vRTOXtYhE"
      },
      "source": [
        "برای تولید تصاویر بریده شده‌ی ۱۰۲۴×۱۰۲۴ از فایل زیر استفاده می‌کنیم\n",
        "\n",
        "--srcpath مکان تصاویر اصلی\n",
        "\n",
        "--dstpath مکان تصاویر خروجی\n",
        "\n",
        "**نکته : در صورت داشتن تصاویر بریده شده اجرای کد زیر نیاز نیست**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4SeBT4utzEk"
      },
      "source": [
        "#آماده سازی dota_1024\n",
        "# %cd /content/ReDet\n",
        "# %run DOTA_devkit/prepare_dota1.py --srcpath /content/drive/Shareddrives/mahdiyar_SBU/data/dota --dstpath /content/drive/Shareddrives/mahdiyar_SBU/data/dota1024new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NByL_MeIs9lU"
      },
      "source": [
        "پس از تولید تصاویر ۱۰۲۴×۱۰۲۴ آن‌ها را به ریپازیتوری پروژه **لینک** می‌کنیم"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k2kF835wffg"
      },
      "source": [
        "#برای مدیریت حافظ از سیمبلیک لینک کمک گرفتم\n",
        "!mkdir '/content/ReDet/data'\n",
        "# !mkdir '/content/AerialDetection/data/dota1_1024'\n",
        "# !ln -s  /content/drive/Shareddrives/mahdiyar_SBU/data/dota1_1024 /content/ReDet/data\n",
        "# !ln -s  /content/drive/Shareddrives/mahdiyar_SBU/data/dota1024new /content/ReDet/data\n",
        "# !ln -s  /content/drive/Shareddrives/mahdiyar_SBU/data/dota_redet /content/ReDet/data\n",
        "!ln -s  /content/drive/Shareddrives/mahdiyar_SBU/data/HRSC2016 /content/ReDet/data\n",
        "!ln -s /content/drive/Shareddrives/mahdiyar_SBU/data/UCAS-AOD /content/ReDet/data\n",
        "!ln -s /content/drive/Shareddrives/mahdiyar_SBU/data/UCAS_AOD659 /content/ReDet/data\n",
        "\n",
        "# !ln -s /content/drive/MyDrive/++ /content/AerialDetection/data/dota1_1024/test1024\n",
        "# !ln -s /content/drive/MyDrive/4++/trainval1024 /content/AerialDetection/data/dota1_1024/trainval1024\n",
        "\n",
        "# !unlink /content/AerialDetection/data/dota1_1024/trainval1024\n",
        "!ln -s /content/drive/MyDrive/4++/work_dirs /content/ReDet\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oG5TnqTplI_"
      },
      "source": [
        "# بررسی حافظه"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEbzqqOJY7Qk"
      },
      "source": [
        "#ممکن است بار اول بعد از ۲ دقیقه خطا دهد. اگر خطا داد دوباره همین دستور اجرا شود (بار دوم خطا نمیدهد)\n",
        "import os\n",
        "\n",
        "# print(len(os.listdir(os.path.join('/content/ReDet/data/dota1_1024/test1024/images'))))\n",
        "print(len(os.listdir(os.path.join('/content/ReDet/data/dota1024new/test1024/images'))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49gzH6svQfIr"
      },
      "source": [
        "#میتوان فولدر را چک کرد(اختیاری)\n",
        "!du -c /content/AerialDetection/data/dota1_1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_EkOnCPppQW"
      },
      "source": [
        "# نصب mmcv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOeH-8AKAPeZ"
      },
      "source": [
        "%cd /content/ReDet\n",
        "!pip install mmcv==0.2.13 #<=0.2.14\n",
        "# !pip install mmcv==0.4.3\n",
        "# !pip install mmcv==1.3.9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeFqZPhZ_s46"
      },
      "source": [
        "# **configs**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFW928ngO45q"
      },
      "source": [
        "نکته ی بسیار مهم در کانفیگ مدل ها تایین زمان ثبت چکپوینت هنگام آموزش، مکان دیتاست می‌باشد"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyqMbxerkgVg"
      },
      "source": [
        "redet config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VPI6CdQ_emr"
      },
      "source": [
        "# %pycat /content/CG-Net/configs/DOTA/faster_rcnn_RoITrans_r101_fpn_baseline.py\n",
        "%%writefile /content/ReDet/configs/ReDet/ReDet_re50_refpn_1x_dota1.py \n",
        "############باید مکان دیتاست و اسم آن در فایل کانفیگ به روز شود در بالای خط دستور تغیر یک خط علامت # گزاشته ام\n",
        "\n",
        "# model settings\n",
        "model = dict(\n",
        "    type='ReDet',\n",
        "    ############################################################################################################\n",
        "    # pretrained='work_dirs/ReResNet_pretrain/re_resnet50_c8_batch256-12933bc2.pth',\n",
        "    pretrained='/content/ReDet/work_dirs/ReResNet_pretrain/re_resnet50_c8_batch256-25b16846.pth',\n",
        "    ############################################################################################################\n",
        "    backbone=dict(\n",
        "        type='ReResNet',\n",
        "        depth=50,\n",
        "        num_stages=4,\n",
        "        out_indices=(0, 1, 2, 3),\n",
        "        frozen_stages=1,\n",
        "        style='pytorch'),\n",
        "    neck=dict(\n",
        "        type='ReFPN',\n",
        "        in_channels=[256, 512, 1024, 2048],\n",
        "        out_channels=256,\n",
        "        num_outs=5),\n",
        "    rpn_head=dict(\n",
        "        type='RPNHead',\n",
        "        in_channels=256,\n",
        "        feat_channels=256,\n",
        "        anchor_scales=[8],\n",
        "        anchor_ratios=[0.5, 1.0, 2.0],\n",
        "        anchor_strides=[4, 8, 16, 32, 64],\n",
        "        target_means=[.0, .0, .0, .0],\n",
        "        target_stds=[1.0, 1.0, 1.0, 1.0],\n",
        "        loss_cls=dict(\n",
        "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
        "        loss_bbox=dict(type='SmoothL1Loss', beta=1.0 / 9.0, loss_weight=1.0)),\n",
        "    bbox_roi_extractor=dict(\n",
        "        type='SingleRoIExtractor',\n",
        "        roi_layer=dict(type='RoIAlign', out_size=7, sample_num=2),\n",
        "        out_channels=256,\n",
        "        featmap_strides=[4, 8, 16, 32]),\n",
        "    bbox_head=dict(\n",
        "        type='SharedFCBBoxHeadRbbox',\n",
        "        num_fcs=2,\n",
        "        in_channels=256,\n",
        "        fc_out_channels=1024,\n",
        "        roi_feat_size=7,\n",
        "        num_classes=16,\n",
        "        target_means=[0., 0., 0., 0., 0.],\n",
        "        target_stds=[0.1, 0.1, 0.2, 0.2, 0.1],\n",
        "        reg_class_agnostic=True,\n",
        "        with_module=False,\n",
        "        loss_cls=dict(\n",
        "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
        "        loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0)),\n",
        "    rbbox_roi_extractor=dict(\n",
        "        type='RboxSingleRoIExtractor',\n",
        "        roi_layer=dict(type='RiRoIAlign', out_size=7, sample_num=2),\n",
        "        out_channels=256,\n",
        "        featmap_strides=[4, 8, 16, 32]),\n",
        "    rbbox_head = dict(\n",
        "        type='SharedFCBBoxHeadRbbox',\n",
        "        num_fcs=2,\n",
        "        in_channels=256,\n",
        "        fc_out_channels=1024,\n",
        "        roi_feat_size=7,\n",
        "        num_classes=16,\n",
        "        target_means=[0., 0., 0., 0., 0.],\n",
        "        target_stds=[0.05, 0.05, 0.1, 0.1, 0.05],\n",
        "        reg_class_agnostic=False,\n",
        "        loss_cls=dict(\n",
        "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
        "        loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))\n",
        "    )\n",
        "# model training and testing settings\n",
        "train_cfg = dict(\n",
        "    rpn=dict(\n",
        "        assigner=dict(\n",
        "            type='MaxIoUAssignerCy',\n",
        "            pos_iou_thr=0.7,\n",
        "            neg_iou_thr=0.3,\n",
        "            min_pos_iou=0.3,\n",
        "            ignore_iof_thr=-1),\n",
        "        sampler=dict(\n",
        "            type='RandomSampler',\n",
        "            num=256,\n",
        "            pos_fraction=0.5,\n",
        "            neg_pos_ub=-1,\n",
        "            add_gt_as_proposals=False),\n",
        "        allowed_border=0,\n",
        "        pos_weight=-1,\n",
        "        debug=False),\n",
        "    rpn_proposal=dict(\n",
        "        nms_across_levels=False,\n",
        "        nms_pre=2000,\n",
        "        nms_post=2000,\n",
        "        max_num=2000,\n",
        "        nms_thr=0.7,\n",
        "        min_bbox_size=0),\n",
        "    rcnn=[\n",
        "        dict(\n",
        "            assigner=dict(\n",
        "                type='MaxIoUAssignerCy',\n",
        "                pos_iou_thr=0.5,\n",
        "                neg_iou_thr=0.5,\n",
        "                min_pos_iou=0.5,\n",
        "                ignore_iof_thr=-1),\n",
        "            sampler=dict(\n",
        "                type='RandomSampler',\n",
        "                num=512,\n",
        "                pos_fraction=0.25,\n",
        "                neg_pos_ub=-1,\n",
        "                add_gt_as_proposals=True),\n",
        "            pos_weight=-1,\n",
        "            debug=False),\n",
        "        dict(\n",
        "            assigner=dict(\n",
        "                type='MaxIoUAssignerRbbox',\n",
        "                pos_iou_thr=0.5,\n",
        "                neg_iou_thr=0.5,\n",
        "                min_pos_iou=0.5,\n",
        "                ignore_iof_thr=-1),\n",
        "            sampler=dict(\n",
        "                type='RandomRbboxSampler',\n",
        "                num=512,\n",
        "                pos_fraction=0.25,\n",
        "                neg_pos_ub=-1,\n",
        "                add_gt_as_proposals=True),\n",
        "            pos_weight=-1,\n",
        "            debug=False)\n",
        "    ])\n",
        "test_cfg = dict(\n",
        "    rpn=dict(\n",
        "        # TODO: test nms 2000\n",
        "        nms_across_levels=False,\n",
        "        nms_pre=2000,\n",
        "        nms_post=2000,\n",
        "        max_num=2000,\n",
        "        nms_thr=0.7,\n",
        "        min_bbox_size=0),\n",
        "    rcnn=dict(\n",
        "        score_thr = 0.05, nms = dict(type='py_cpu_nms_poly_fast', iou_thr=0.1), max_per_img = 2000)\n",
        ")\n",
        "# dataset settings\n",
        "dataset_type = 'DOTADataset'\n",
        "########################################################################################################################\n",
        "# data_root = '/content/ReDet/data/dota1_1024/'\n",
        "# data_root = '/content/ReDet/data/dota_redet/'\n",
        "data_root = '/content/ReDet/data/dota1024new/'\n",
        "########################################################################################################################\n",
        "img_norm_cfg = dict(\n",
        "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
        "data = dict(\n",
        "    imgs_per_gpu=2,\n",
        "    workers_per_gpu=2,\n",
        "    train=dict(\n",
        "        type=dataset_type,\n",
        "        ####################################################################################\n",
        "        ann_file=data_root + 'trainval1024/DOTA_trainval1024.json',\n",
        "        img_prefix=data_root + 'trainval1024/images',\n",
        "        img_scale=(1024, 1024),\n",
        "        img_norm_cfg=img_norm_cfg,\n",
        "        size_divisor=32,\n",
        "        flip_ratio=0.5,\n",
        "        with_mask=True,\n",
        "        with_crowd=True,\n",
        "        with_label=True),\n",
        "    val=dict(\n",
        "        type=dataset_type,\n",
        "        ann_file=data_root + 'trainval1024/DOTA_trainval1024.json',\n",
        "        img_prefix=data_root + 'trainval1024/images',\n",
        "        img_scale=(1024, 1024),\n",
        "        img_norm_cfg=img_norm_cfg,\n",
        "        size_divisor=32,\n",
        "        flip_ratio=0,\n",
        "        with_mask=True,\n",
        "        with_crowd=True,\n",
        "        with_label=True),\n",
        "    test=dict(\n",
        "        type=dataset_type,\n",
        "        #############################################################################################\n",
        "        ann_file=data_root + 'test1024/DOTA_test1024.json',\n",
        "        # ann_file=data_root + 'val1024/DOTA_val1024.json',\n",
        "        img_prefix=data_root + 'test1024/images',\n",
        "        # img_prefix=data_root + 'val1024/images',\n",
        "        img_scale=(1024, 1024),\n",
        "        img_norm_cfg=img_norm_cfg,\n",
        "        size_divisor=32,\n",
        "        flip_ratio=0,\n",
        "        with_mask=False,\n",
        "        with_label=False,\n",
        "        test_mode=True))\n",
        "        ####################################################################################\n",
        "# optimizer\n",
        "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
        "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
        "# learning policy\n",
        "lr_config = dict(\n",
        "    policy='step',\n",
        "    warmup='linear',\n",
        "    warmup_iters=500,\n",
        "    warmup_ratio=1.0 / 3,\n",
        "    step=[8, 11])\n",
        "checkpoint_config = dict(interval=12)\n",
        "# yapf:disable\n",
        "log_config = dict(\n",
        "    interval=50,\n",
        "    hooks=[\n",
        "        dict(type='TextLoggerHook'),\n",
        "        ####################################################################################\n",
        "        dict(type='TensorboardLoggerHook')\n",
        "    ])\n",
        "# yapf:enable\n",
        "# runtime settings\n",
        "total_epochs = 12\n",
        "dist_params = dict(backend='nccl')\n",
        "log_level = 'INFO'\n",
        "work_dir = './work_dirs/ReDet_re50_refpn_1x_dota1'\n",
        "load_from = None\n",
        "resume_from = None\n",
        "workflow = [('train', 1)]\n",
        "\n",
        "############################################################################################\n",
        "# map: 0.7625466854468368\n",
        "# classaps:  [88.78856374 82.64427543 53.97022743 73.99912889 78.12618094 84.05574561\n",
        "# 88.03844621 90.88860051 87.78155929 85.75268025 61.76308434 60.39378975\n",
        "# 75.9600904  68.06737265 63.59028274]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc2NZ3vs9ZBd"
      },
      "source": [
        "**HRSC2016** ReDet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAQ8eguG9YKP"
      },
      "source": [
        "%%writefile /content/ReDet/configs/ReDet/ReDet_re50_refpn_3x_hrsc2016.py\n",
        "\n",
        "# model settings\n",
        "model = dict(\n",
        "    type='ReDet',\n",
        "    pretrained='/content/ReDet/work_dirs/ReResNet_pretrain/re_resnet50_c8_batch256-25b16846.pth',\n",
        "    backbone=dict(\n",
        "        type='ReResNet',\n",
        "        depth=50,\n",
        "        num_stages=4,\n",
        "        out_indices=(0, 1, 2, 3),\n",
        "        frozen_stages=1,\n",
        "        style='pytorch'),\n",
        "    neck=dict(\n",
        "        type='ReFPN',\n",
        "        in_channels=[256, 512, 1024, 2048],\n",
        "        out_channels=256,\n",
        "        num_outs=5),\n",
        "    rpn_head=dict(\n",
        "        type='RPNHead',\n",
        "        in_channels=256,\n",
        "        feat_channels=256,\n",
        "        anchor_scales=[8],\n",
        "        anchor_ratios=[0.5, 1.0, 2.0],\n",
        "        anchor_strides=[4, 8, 16, 32, 64],\n",
        "        target_means=[.0, .0, .0, .0],\n",
        "        target_stds=[1.0, 1.0, 1.0, 1.0],\n",
        "        loss_cls=dict(\n",
        "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
        "        loss_bbox=dict(type='SmoothL1Loss', beta=1.0 / 9.0, loss_weight=1.0)),\n",
        "    bbox_roi_extractor=dict(\n",
        "        type='SingleRoIExtractor',\n",
        "        roi_layer=dict(type='RoIAlign', out_size=7, sample_num=2),\n",
        "        out_channels=256,\n",
        "        featmap_strides=[4, 8, 16, 32]),\n",
        "    bbox_head=dict(\n",
        "        type='SharedFCBBoxHeadRbbox',\n",
        "        num_fcs=2,\n",
        "        in_channels=256,\n",
        "        fc_out_channels=1024,\n",
        "        roi_feat_size=7,\n",
        "        num_classes=2,\n",
        "        target_means=[0., 0., 0., 0., 0.],\n",
        "        target_stds=[0.1, 0.1, 0.2, 0.2, 0.1],\n",
        "        reg_class_agnostic=True,\n",
        "        with_module=False,\n",
        "        loss_cls=dict(\n",
        "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
        "        loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0)),\n",
        "    rbbox_roi_extractor=dict(\n",
        "        type='RboxSingleRoIExtractor',\n",
        "        roi_layer=dict(type='RiRoIAlign', out_size=7, sample_num=2),\n",
        "        out_channels=256,\n",
        "        featmap_strides=[4, 8, 16, 32]),\n",
        "    rbbox_head = dict(\n",
        "        type='SharedFCBBoxHeadRbbox',\n",
        "        num_fcs=2,\n",
        "        in_channels=256,\n",
        "        fc_out_channels=1024,\n",
        "        roi_feat_size=7,\n",
        "        num_classes=2,\n",
        "        target_means=[0., 0., 0., 0., 0.],\n",
        "        target_stds=[0.05, 0.05, 0.1, 0.1, 0.05],\n",
        "        reg_class_agnostic=False,\n",
        "        loss_cls=dict(\n",
        "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
        "        loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))\n",
        "    )\n",
        "# model training and testing settings\n",
        "train_cfg = dict(\n",
        "    rpn=dict(\n",
        "        assigner=dict(\n",
        "            type='MaxIoUAssignerCy',\n",
        "            pos_iou_thr=0.7,\n",
        "            neg_iou_thr=0.3,\n",
        "            min_pos_iou=0.3,\n",
        "            ignore_iof_thr=-1),\n",
        "        sampler=dict(\n",
        "            type='RandomSampler',\n",
        "            num=256,\n",
        "            pos_fraction=0.5,\n",
        "            neg_pos_ub=-1,\n",
        "            add_gt_as_proposals=False),\n",
        "        allowed_border=0,\n",
        "        pos_weight=-1,\n",
        "        debug=False),\n",
        "    rpn_proposal=dict(\n",
        "        nms_across_levels=False,\n",
        "        nms_pre=2000,\n",
        "        nms_post=2000,\n",
        "        max_num=2000,\n",
        "        nms_thr=0.7,\n",
        "        min_bbox_size=0),\n",
        "    rcnn=[\n",
        "        dict(\n",
        "            assigner=dict(\n",
        "                type='MaxIoUAssignerCy',\n",
        "                pos_iou_thr=0.5,\n",
        "                neg_iou_thr=0.5,\n",
        "                min_pos_iou=0.5,\n",
        "                ignore_iof_thr=-1),\n",
        "            sampler=dict(\n",
        "                type='RandomSampler',\n",
        "                num=512,\n",
        "                pos_fraction=0.25,\n",
        "                neg_pos_ub=-1,\n",
        "                add_gt_as_proposals=True),\n",
        "            pos_weight=-1,\n",
        "            debug=False),\n",
        "        dict(\n",
        "            assigner=dict(\n",
        "                type='MaxIoUAssignerRbbox',\n",
        "                pos_iou_thr=0.5,\n",
        "                neg_iou_thr=0.5,\n",
        "                min_pos_iou=0.5,\n",
        "                ignore_iof_thr=-1),\n",
        "            sampler=dict(\n",
        "                type='RandomRbboxSampler',\n",
        "                num=512,\n",
        "                pos_fraction=0.25,\n",
        "                neg_pos_ub=-1,\n",
        "                add_gt_as_proposals=True),\n",
        "            pos_weight=-1,\n",
        "            debug=False)\n",
        "    ])\n",
        "test_cfg = dict(\n",
        "    rpn=dict(\n",
        "        # TODO: test nms 2000\n",
        "        nms_across_levels=False,\n",
        "        nms_pre=2000,\n",
        "        nms_post=2000,\n",
        "        max_num=2000,\n",
        "        nms_thr=0.7,\n",
        "        min_bbox_size=0),\n",
        "    rcnn=dict(\n",
        "        score_thr = 0.05, nms = dict(type='py_cpu_nms_poly_fast', iou_thr=0.1), max_per_img = 2000)\n",
        ")\n",
        "# dataset settings\n",
        "dataset_type = 'HRSCL1Dataset'\n",
        "###################################################################################\n",
        "data_root = '/content/ReDet/data/HRSC2016/'########################################\n",
        "###################################################################################\n",
        "img_norm_cfg = dict(\n",
        "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
        "data = dict(\n",
        "    imgs_per_gpu=2,\n",
        "    workers_per_gpu=2,\n",
        "    train=dict(\n",
        "        type=dataset_type,\n",
        "        ann_file=data_root + 'Train/HRSC_L1_train.json',\n",
        "        img_prefix=data_root + 'Train/images/',\n",
        "        img_scale=(800, 512),\n",
        "        img_norm_cfg=img_norm_cfg,\n",
        "        size_divisor=32,\n",
        "        flip_ratio=0.5,\n",
        "        with_mask=True,\n",
        "        with_crowd=True,\n",
        "        with_label=True),\n",
        "    val=dict(\n",
        "        type=dataset_type,\n",
        "        ann_file=data_root + 'Test/HRSC_L1_test.json',\n",
        "        img_prefix=data_root + 'Test/images/',\n",
        "        img_scale=(800, 512),\n",
        "        img_norm_cfg=img_norm_cfg,\n",
        "        size_divisor=32,\n",
        "        flip_ratio=0,\n",
        "        with_mask=True,\n",
        "        with_crowd=True,\n",
        "        with_label=True),\n",
        "    test=dict(\n",
        "        type=dataset_type,\n",
        "        ann_file=data_root + 'Test/HRSC_L1_test.json',\n",
        "        img_prefix=data_root + 'Test/images/',\n",
        "        img_scale=(800, 512),\n",
        "        img_norm_cfg=img_norm_cfg,\n",
        "        size_divisor=32,\n",
        "        flip_ratio=0,\n",
        "        with_mask=False,\n",
        "        with_label=False,\n",
        "        test_mode=True))\n",
        "# optimizer\n",
        "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
        "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
        "# learning policy\n",
        "lr_config = dict(\n",
        "    policy='step',\n",
        "    warmup='linear',\n",
        "    warmup_iters=500,\n",
        "    warmup_ratio=1.0 / 3,\n",
        "    step=[24, 33])\n",
        "checkpoint_config = dict(interval=1)\n",
        "# yapf:disable\n",
        "log_config = dict(\n",
        "    interval=1,\n",
        "    hooks=[\n",
        "        dict(type='TextLoggerHook'),\n",
        "        dict(type='TensorboardLoggerHook')\n",
        "    ])\n",
        "# yapf:enable\n",
        "# runtime settings\n",
        "total_epochs = 36\n",
        "dist_params = dict(backend='nccl')\n",
        "log_level = 'INFO'\n",
        "work_dir = '/content/ReDet/work_dirs/ReDet_re50_refpn_3x_hrsc2016'\n",
        "load_from = None\n",
        "resume_from = None\n",
        "workflow = [('train', 1)]\n",
        "\n",
        "# VOC2007 metrics\n",
        "# AP50: 90.46     AP75: 89.46      mAP: 70.41"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR_FFp_-kmqJ"
      },
      "source": [
        "faster_rcnn_RoITrans_r50_fpn_1x_dota config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxmi-iv7ksJx"
      },
      "source": [
        "# %pycat /content/ReDet/configs/DOTA/faster_rcnn_RoITrans_r50_fpn_1x_dota.py\n",
        "%%writefile /content/ReDet/configs/DOTA/faster_rcnn_RoITrans_r50_fpn_1x_dota.py\n",
        "##########این کانفیگ از ریپازیتوری اصلی کپی شده\n",
        "\n",
        "# model settings\n",
        "model = dict(\n",
        "    type='RoITransformer',\n",
        "    pretrained='modelzoo://resnet50',\n",
        "    backbone=dict(\n",
        "        type='ResNet',\n",
        "        depth=50,\n",
        "        num_stages=4,\n",
        "        out_indices=(0, 1, 2, 3),\n",
        "        frozen_stages=1,\n",
        "        style='pytorch'),\n",
        "    neck=dict(\n",
        "        type='FPN',\n",
        "        in_channels=[256, 512, 1024, 2048],\n",
        "        out_channels=256,\n",
        "        num_outs=5),\n",
        "    rpn_head=dict(\n",
        "        type='RPNHead',\n",
        "        in_channels=256,\n",
        "        feat_channels=256,\n",
        "        anchor_scales=[8],\n",
        "        anchor_ratios=[0.5, 1.0, 2.0],\n",
        "        anchor_strides=[4, 8, 16, 32, 64],\n",
        "        target_means=[.0, .0, .0, .0],\n",
        "        target_stds=[1.0, 1.0, 1.0, 1.0],\n",
        "        loss_cls=dict(\n",
        "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
        "        loss_bbox=dict(type='SmoothL1Loss', beta=1.0 / 9.0, loss_weight=1.0)),\n",
        "    bbox_roi_extractor=dict(\n",
        "        type='SingleRoIExtractor',\n",
        "        roi_layer=dict(type='RoIAlign', out_size=7, sample_num=2),\n",
        "        out_channels=256,\n",
        "        featmap_strides=[4, 8, 16, 32]),\n",
        "    bbox_head=dict(\n",
        "        type='SharedFCBBoxHeadRbbox',\n",
        "        num_fcs=2,\n",
        "        in_channels=256,\n",
        "        fc_out_channels=1024,\n",
        "        roi_feat_size=7,\n",
        "        num_classes=16,\n",
        "        target_means=[0., 0., 0., 0., 0.],\n",
        "        target_stds=[0.1, 0.1, 0.2, 0.2, 0.1],\n",
        "        reg_class_agnostic=True,\n",
        "        with_module=False,\n",
        "        loss_cls=dict(\n",
        "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
        "        loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0)),\n",
        "    rbbox_roi_extractor=dict(\n",
        "        type='RboxSingleRoIExtractor',\n",
        "        roi_layer=dict(type='RoIAlignRotated', out_size=7, sample_num=2),\n",
        "        out_channels=256,\n",
        "        featmap_strides=[4, 8, 16, 32]),\n",
        "    rbbox_head = dict(\n",
        "        type='SharedFCBBoxHeadRbbox',\n",
        "        num_fcs=2,\n",
        "        in_channels=256,\n",
        "        fc_out_channels=1024,\n",
        "        roi_feat_size=7,\n",
        "        num_classes=16,\n",
        "        target_means=[0., 0., 0., 0., 0.],\n",
        "        target_stds=[0.05, 0.05, 0.1, 0.1, 0.05],\n",
        "        reg_class_agnostic=False,\n",
        "        loss_cls=dict(\n",
        "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
        "        loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))\n",
        "    )\n",
        "# model training and testing settings\n",
        "train_cfg = dict(\n",
        "    rpn=dict(\n",
        "        assigner=dict(\n",
        "            type='MaxIoUAssignerCy',\n",
        "            pos_iou_thr=0.7,\n",
        "            neg_iou_thr=0.3,\n",
        "            min_pos_iou=0.3,\n",
        "            ignore_iof_thr=-1),\n",
        "        sampler=dict(\n",
        "            type='RandomSampler',\n",
        "            num=256,\n",
        "            pos_fraction=0.5,\n",
        "            neg_pos_ub=-1,\n",
        "            add_gt_as_proposals=False),\n",
        "        allowed_border=0,\n",
        "        pos_weight=-1,\n",
        "        debug=False),\n",
        "    rpn_proposal=dict(\n",
        "        nms_across_levels=False,\n",
        "        nms_pre=2000,\n",
        "        nms_post=2000,\n",
        "        max_num=2000,\n",
        "        nms_thr=0.7,\n",
        "        min_bbox_size=0),\n",
        "    rcnn=[\n",
        "        dict(\n",
        "            assigner=dict(\n",
        "                type='MaxIoUAssignerCy',\n",
        "                pos_iou_thr=0.5,\n",
        "                neg_iou_thr=0.5,\n",
        "                min_pos_iou=0.5,\n",
        "                ignore_iof_thr=-1),\n",
        "            sampler=dict(\n",
        "                type='RandomSampler',\n",
        "                num=512,\n",
        "                pos_fraction=0.25,\n",
        "                neg_pos_ub=-1,\n",
        "                add_gt_as_proposals=True),\n",
        "            pos_weight=-1,\n",
        "            debug=False),\n",
        "        dict(\n",
        "            assigner=dict(\n",
        "                type='MaxIoUAssignerRbbox',\n",
        "                pos_iou_thr=0.5,\n",
        "                neg_iou_thr=0.5,\n",
        "                min_pos_iou=0.5,\n",
        "                ignore_iof_thr=-1),\n",
        "            sampler=dict(\n",
        "                type='RandomRbboxSampler',\n",
        "                num=512,\n",
        "                pos_fraction=0.25,\n",
        "                neg_pos_ub=-1,\n",
        "                add_gt_as_proposals=True),\n",
        "            pos_weight=-1,\n",
        "            debug=False)\n",
        "    ])\n",
        "test_cfg = dict(\n",
        "    rpn=dict(\n",
        "        # TODO: test nms 2000\n",
        "        nms_across_levels=False,\n",
        "        nms_pre=2000,\n",
        "        nms_post=2000,\n",
        "        max_num=2000,\n",
        "        nms_thr=0.7,\n",
        "        min_bbox_size=0),\n",
        "    rcnn=dict(\n",
        "        # score_thr=0.05, nms=dict(type='py_cpu_nms_poly_fast', iou_thr=0.1), max_per_img=1000)\n",
        "        score_thr = 0.05, nms = dict(type='py_cpu_nms_poly_fast', iou_thr=0.1), max_per_img = 2000)\n",
        "        # score_thr = 0.001, nms = dict(type='pesudo_nms_poly', iou_thr=0.9), max_per_img = 2000)\n",
        "        # score_thr = 0.001, nms = dict(type='py_cpu_nms_poly_fast', iou_thr=0.1), max_per_img = 2000)\n",
        "\n",
        "# soft-nms is also supported for rcnn testing\n",
        "    # e.g., nms=dict(type='soft_nms', iou_thr=0.5, min_score=0.05)\n",
        ")\n",
        "# dataset settings\n",
        "dataset_type = 'DOTADataset'\n",
        "######################################################################################################################\n",
        "# data_root = '/content/ReDet/data/dota1_1024/'\n",
        "# data_root = '/content/ReDet/data/dota_redet/'\n",
        "data_root = '/content/ReDet/data/dota1024new/'\n",
        "######################################################################################################################\n",
        "img_norm_cfg = dict(\n",
        "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
        "data = dict(\n",
        "    imgs_per_gpu=2,\n",
        "    workers_per_gpu=2,\n",
        "    train=dict(\n",
        "        type=dataset_type,\n",
        "        ann_file=data_root + 'trainval1024/DOTA_trainval1024.json',\n",
        "        img_prefix=data_root + 'trainval1024/images/',\n",
        "        img_scale=(1024, 1024),\n",
        "        img_norm_cfg=img_norm_cfg,\n",
        "        size_divisor=32,\n",
        "        flip_ratio=0.5,\n",
        "        with_mask=True,\n",
        "        with_crowd=True,\n",
        "        with_label=True),\n",
        "    val=dict(\n",
        "        type=dataset_type,\n",
        "        ann_file=data_root + 'trainval1024/DOTA_trainval1024.json',\n",
        "        img_prefix=data_root + 'trainval1024/images',\n",
        "        img_scale=(1024, 1024),\n",
        "        img_norm_cfg=img_norm_cfg,\n",
        "        size_divisor=32,\n",
        "        flip_ratio=0,\n",
        "        with_mask=True,\n",
        "        with_crowd=True,\n",
        "        with_label=True),\n",
        "    test=dict(\n",
        "        type=dataset_type,\n",
        "        #############################################################################################\n",
        "        ann_file=data_root + 'test1024/DOTA_test1024.json',\n",
        "        # ann_file=data_root + 'val1024/DOTA_val1024.json',\n",
        "        img_prefix=data_root + 'test1024/images',\n",
        "        # img_prefix=data_root + 'val1024/images',\n",
        "        # ann_file=data_root + 'test1024_ms/DOTA_test1024_ms.json',\n",
        "        # img_prefix=data_root + 'test1024_ms/images',\n",
        "        img_scale=(1024, 1024),\n",
        "        img_norm_cfg=img_norm_cfg,\n",
        "        size_divisor=32,\n",
        "        flip_ratio=0,\n",
        "        with_mask=False,\n",
        "        with_label=False,\n",
        "        test_mode=True))\n",
        "# optimizer\n",
        "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
        "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
        "# learning policy\n",
        "lr_config = dict(\n",
        "    policy='step',\n",
        "    warmup='linear',\n",
        "    warmup_iters=500,\n",
        "    warmup_ratio=1.0 / 3,\n",
        "    step=[8, 11])\n",
        "checkpoint_config = dict(interval=1)\n",
        "# yapf:disable\n",
        "log_config = dict(\n",
        "    interval=50,\n",
        "    hooks=[\n",
        "        dict(type='TextLoggerHook'),\n",
        "        # dict(type='TensorboardLoggerHook')\n",
        "    ])\n",
        "# yapf:enable\n",
        "# runtime settings\n",
        "total_epochs = 12\n",
        "dist_params = dict(backend='nccl')\n",
        "log_level = 'INFO'\n",
        "work_dir = './work_dirs/faster_rcnn_RoITrans_r50_fpn_1x_dota'\n",
        "load_from = None\n",
        "resume_from = None\n",
        "workflow = [('train', 1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvXb_kMfnSau"
      },
      "source": [
        "faster_rcnn_obb_r50_fpn_1x_dota config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HIXmti_nBtI"
      },
      "source": [
        "# %pycat /content/ReDet/configs/DOTA/faster_rcnn_obb_r50_fpn_1x_dota.py\n",
        "%%writefile /content/ReDet/configs/UCAS_AOD/faster_rcnn_RoITrans_r50_fpn_3x_UCAS_AOD.py\n",
        "##########این کانفیگ از ریپازیتوری اصلی کپی شده\n",
        "\n",
        "\n",
        "\n",
        "# model settings\n",
        "model = dict(\n",
        "    type='FasterRCNNOBB',\n",
        "    pretrained='modelzoo://resnet50',\n",
        "    backbone=dict(\n",
        "        type='ResNet',\n",
        "        depth=50,\n",
        "        num_stages=4,\n",
        "        out_indices=(0, 1, 2, 3),\n",
        "        frozen_stages=1,\n",
        "        style='pytorch'),\n",
        "    neck=dict(\n",
        "        type='FPN',\n",
        "        in_channels=[256, 512, 1024, 2048],\n",
        "        out_channels=256,\n",
        "        num_outs=5),\n",
        "    rpn_head=dict(\n",
        "        type='RPNHead',\n",
        "        in_channels=256,\n",
        "        feat_channels=256,\n",
        "        anchor_scales=[8],\n",
        "        anchor_ratios=[0.5, 1.0, 2.0],\n",
        "        anchor_strides=[4, 8, 16, 32, 64],\n",
        "        target_means=[.0, .0, .0, .0],\n",
        "        target_stds=[1.0, 1.0, 1.0, 1.0],\n",
        "        loss_cls=dict(\n",
        "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
        "        loss_bbox=dict(type='SmoothL1Loss', beta=1.0 / 9.0, loss_weight=1.0)),\n",
        "    bbox_roi_extractor=dict(\n",
        "        type='SingleRoIExtractor',\n",
        "        roi_layer=dict(type='RoIAlign', out_size=7, sample_num=2),\n",
        "        out_channels=256,\n",
        "        featmap_strides=[4, 8, 16, 32]),\n",
        "    bbox_head=dict(\n",
        "        type='SharedFCBBoxHeadRbbox',\n",
        "        num_fcs=2,\n",
        "        in_channels=256,\n",
        "        fc_out_channels=1024,\n",
        "        roi_feat_size=7,\n",
        "        num_classes=16,\n",
        "        target_means=[0., 0., 0., 0., 0.],\n",
        "        target_stds=[0.1, 0.1, 0.2, 0.2, 0.1],\n",
        "        reg_class_agnostic=False,\n",
        "        with_module=False,\n",
        "        hbb_trans='hbbpolyobb',\n",
        "        loss_cls=dict(\n",
        "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
        "        loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0)))\n",
        "# model training and testing settings\n",
        "train_cfg = dict(\n",
        "    rpn=dict(\n",
        "        assigner=dict(\n",
        "            type='MaxIoUAssignerCy',\n",
        "            pos_iou_thr=0.7,\n",
        "            neg_iou_thr=0.3,\n",
        "            min_pos_iou=0.3,\n",
        "            ignore_iof_thr=-1),\n",
        "        sampler=dict(\n",
        "            type='RandomSampler',\n",
        "            num=256,\n",
        "            pos_fraction=0.5,\n",
        "            neg_pos_ub=-1,\n",
        "            add_gt_as_proposals=False),\n",
        "        allowed_border=0,\n",
        "        pos_weight=-1,\n",
        "        debug=False),\n",
        "    rpn_proposal=dict(\n",
        "        nms_across_levels=False,\n",
        "        nms_pre=2000,\n",
        "        nms_post=2000,\n",
        "        max_num=2000,\n",
        "        nms_thr=0.7,\n",
        "        min_bbox_size=0),\n",
        "    rcnn=dict(\n",
        "        assigner=dict(\n",
        "            type='MaxIoUAssignerCy',\n",
        "            pos_iou_thr=0.5,\n",
        "            neg_iou_thr=0.5,\n",
        "            min_pos_iou=0.5,\n",
        "            ignore_iof_thr=-1),\n",
        "        sampler=dict(\n",
        "            type='RandomSampler',\n",
        "            num=512,\n",
        "            pos_fraction=0.25,\n",
        "            neg_pos_ub=-1,\n",
        "            add_gt_as_proposals=True),\n",
        "        pos_weight=-1,\n",
        "        debug=False))\n",
        "test_cfg = dict(\n",
        "    rpn=dict(\n",
        "        nms_across_levels=False,\n",
        "        nms_pre=2000,\n",
        "        nms_post=2000,\n",
        "        max_num=2000,\n",
        "        nms_thr=0.7,\n",
        "        min_bbox_size=0),\n",
        "    rcnn=dict(\n",
        "        # score_thr=0.05, nms=dict(type='py_cpu_nms_poly_fast', iou_thr=0.1), max_per_img=1000)\n",
        "    score_thr = 0.05, nms = dict(type='py_cpu_nms_poly_fast', iou_thr=0.1), max_per_img = 2000)\n",
        "# soft-nms is also supported for rcnn testing\n",
        "    # e.g., nms=dict(type='soft_nms', iou_thr=0.5, min_score=0.05)\n",
        ")\n",
        "# dataset settings\n",
        "dataset_type = 'DOTADataset'\n",
        "#################################################################################################################\n",
        "# data_root = '/content/ReDet/data/dota1_1024/'\n",
        "# data_root = '/content/ReDet/data/dota_redet/'\n",
        "data_root = '/content/ReDet/data/dota1024new/'\n",
        "#################################################################################################################\n",
        "img_norm_cfg = dict(\n",
        "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
        "data = dict(\n",
        "    imgs_per_gpu=2,\n",
        "    workers_per_gpu=2,\n",
        "    train=dict(\n",
        "        type=dataset_type,\n",
        "        ann_file=data_root + 'trainval1024/DOTA_trainval1024.json',\n",
        "        img_prefix=data_root + 'trainval1024/images/',\n",
        "        img_scale=(1024, 1024),\n",
        "        img_norm_cfg=img_norm_cfg,\n",
        "        size_divisor=32,\n",
        "        flip_ratio=0.5,\n",
        "        with_mask=True,\n",
        "        with_crowd=True,\n",
        "        with_label=True),\n",
        "    val=dict(\n",
        "        type=dataset_type,\n",
        "        ann_file=data_root + 'trainval1024/DOTA_trainval1024.json',\n",
        "        img_prefix=data_root + 'trainval1024/images',\n",
        "        img_scale=(1024, 1024),\n",
        "        img_norm_cfg=img_norm_cfg,\n",
        "        size_divisor=32,\n",
        "        flip_ratio=0,\n",
        "        with_mask=True,\n",
        "        with_crowd=True,\n",
        "        with_label=True),\n",
        "    test=dict(\n",
        "        type=dataset_type,\n",
        "        #############################################################################################\n",
        "        ann_file=data_root + 'test1024/DOTA_test1024.json',\n",
        "        # ann_file=data_root + 'val1024/DOTA_val1024.json',\n",
        "        img_prefix=data_root + 'test1024/images',\n",
        "        # img_prefix=data_root + 'val1024/images',\n",
        "        img_scale=(1024, 1024),\n",
        "        img_norm_cfg=img_norm_cfg,\n",
        "        size_divisor=32,\n",
        "        flip_ratio=0,\n",
        "        with_mask=False,\n",
        "        with_label=False,\n",
        "        test_mode=True))\n",
        "# optimizer\n",
        "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
        "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
        "# learning policy\n",
        "lr_config = dict(\n",
        "    policy='step',\n",
        "    warmup='linear',\n",
        "    warmup_iters=500,\n",
        "    warmup_ratio=1.0 / 3,\n",
        "    step=[8, 11])\n",
        "checkpoint_config = dict(interval=1)\n",
        "# yapf:disable\n",
        "log_config = dict(\n",
        "    interval=1,\n",
        "    hooks=[\n",
        "        dict(type='TextLoggerHook'),\n",
        "        dict(type='TensorboardLoggerHook')\n",
        "    ])\n",
        "# yapf:enable\n",
        "# runtime settings\n",
        "total_epochs = 12\n",
        "dist_params = dict(backend='nccl')\n",
        "log_level = 'INFO'\n",
        "work_dir = './work_dirs/faster_rcnn_obb_r50_fpn_1x_dota'\n",
        "load_from = None\n",
        "resume_from = None\n",
        "workflow = [('train', 1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vCsRuVLvdOY"
      },
      "source": [
        "# UCAS_AOD config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0suQT4_Ivf_U"
      },
      "source": [
        "# %pycat /content/ReDet/configs/DOTA/faster_rcnn_RoITrans_r50_fpn_1x_dota.py\n",
        "%%writefile /content/ReDet/configs/UCAS_AOD/faster_rcnn_RoITrans_r50_fpn_3x_UCAS_AOD.py\n",
        "##########این کانفیگ از ریپازیتوری اصلی کپی شده\n",
        "\n",
        "# model settings\n",
        "model = dict(\n",
        "    type='RoITransformer',\n",
        "    pretrained='modelzoo://resnet50',\n",
        "    backbone=dict(\n",
        "        type='ResNet',\n",
        "        depth=50,\n",
        "        num_stages=4,\n",
        "        out_indices=(0, 1, 2, 3),\n",
        "        frozen_stages=1,\n",
        "        style='pytorch'),\n",
        "    neck=dict(\n",
        "        type='FPN',\n",
        "        in_channels=[256, 512, 1024, 2048],\n",
        "        out_channels=256,\n",
        "        num_outs=5),\n",
        "    rpn_head=dict(\n",
        "        type='RPNHead',\n",
        "        in_channels=256,\n",
        "        feat_channels=256,\n",
        "        anchor_scales=[8],\n",
        "        anchor_ratios=[0.5, 1.0, 2.0],\n",
        "        anchor_strides=[4, 8, 16, 32, 64],\n",
        "        target_means=[.0, .0, .0, .0],\n",
        "        target_stds=[1.0, 1.0, 1.0, 1.0],\n",
        "        loss_cls=dict(\n",
        "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
        "        loss_bbox=dict(type='SmoothL1Loss', beta=1.0 / 9.0, loss_weight=1.0)),\n",
        "    bbox_roi_extractor=dict(\n",
        "        type='SingleRoIExtractor',\n",
        "        roi_layer=dict(type='RoIAlign', out_size=7, sample_num=2),\n",
        "        out_channels=256,\n",
        "        featmap_strides=[4, 8, 16, 32]),\n",
        "    bbox_head=dict(\n",
        "        type='SharedFCBBoxHeadRbbox',\n",
        "        num_fcs=2,\n",
        "        in_channels=256,\n",
        "        fc_out_channels=1024,\n",
        "        roi_feat_size=7,\n",
        "        ##############################################\n",
        "        num_classes=2,\n",
        "        target_means=[0., 0., 0., 0., 0.],\n",
        "        target_stds=[0.1, 0.1, 0.2, 0.2, 0.1],\n",
        "        reg_class_agnostic=True,\n",
        "        with_module=False,\n",
        "        loss_cls=dict(\n",
        "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
        "        loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0)),\n",
        "    rbbox_roi_extractor=dict(\n",
        "        type='RboxSingleRoIExtractor',\n",
        "        roi_layer=dict(type='RoIAlignRotated', out_size=7, sample_num=2),\n",
        "        out_channels=256,\n",
        "        featmap_strides=[4, 8, 16, 32]),\n",
        "    rbbox_head = dict(\n",
        "        type='SharedFCBBoxHeadRbbox',\n",
        "        num_fcs=2,\n",
        "        in_channels=256,\n",
        "        fc_out_channels=1024,\n",
        "        roi_feat_size=7,\n",
        "        ###################################################\n",
        "        num_classes=2,\n",
        "        target_means=[0., 0., 0., 0., 0.],\n",
        "        target_stds=[0.05, 0.05, 0.1, 0.1, 0.05],\n",
        "        reg_class_agnostic=False,\n",
        "        loss_cls=dict(\n",
        "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
        "        loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))\n",
        "    )\n",
        "# model training and testing settings\n",
        "train_cfg = dict(\n",
        "    rpn=dict(\n",
        "        assigner=dict(\n",
        "            type='MaxIoUAssignerCy',\n",
        "            pos_iou_thr=0.7,\n",
        "            neg_iou_thr=0.3,\n",
        "            min_pos_iou=0.3,\n",
        "            ignore_iof_thr=-1),\n",
        "        sampler=dict(\n",
        "            type='RandomSampler',\n",
        "            num=256,\n",
        "            pos_fraction=0.5,\n",
        "            neg_pos_ub=-1,\n",
        "            add_gt_as_proposals=False),\n",
        "        allowed_border=0,\n",
        "        pos_weight=-1,\n",
        "        debug=False),\n",
        "    rpn_proposal=dict(\n",
        "        nms_across_levels=False,\n",
        "        nms_pre=2000,\n",
        "        nms_post=2000,\n",
        "        max_num=2000,\n",
        "        nms_thr=0.7,\n",
        "        min_bbox_size=0),\n",
        "    rcnn=[\n",
        "        dict(\n",
        "            assigner=dict(\n",
        "                type='MaxIoUAssignerCy',\n",
        "                pos_iou_thr=0.5,\n",
        "                neg_iou_thr=0.5,\n",
        "                min_pos_iou=0.5,\n",
        "                ignore_iof_thr=-1),\n",
        "            sampler=dict(\n",
        "                type='RandomSampler',\n",
        "                num=512,\n",
        "                pos_fraction=0.25,\n",
        "                neg_pos_ub=-1,\n",
        "                add_gt_as_proposals=True),\n",
        "            pos_weight=-1,\n",
        "            debug=False),\n",
        "        dict(\n",
        "            assigner=dict(\n",
        "                type='MaxIoUAssignerRbbox',\n",
        "                pos_iou_thr=0.5,\n",
        "                neg_iou_thr=0.5,\n",
        "                min_pos_iou=0.5,\n",
        "                ignore_iof_thr=-1),\n",
        "            sampler=dict(\n",
        "                type='RandomRbboxSampler',\n",
        "                num=512,\n",
        "                pos_fraction=0.25,\n",
        "                neg_pos_ub=-1,\n",
        "                add_gt_as_proposals=True),\n",
        "            pos_weight=-1,\n",
        "            debug=False)\n",
        "    ])\n",
        "test_cfg = dict(\n",
        "    rpn=dict(\n",
        "        # TODO: test nms 2000\n",
        "        nms_across_levels=False,\n",
        "        nms_pre=2000,\n",
        "        nms_post=2000,\n",
        "        max_num=2000,\n",
        "        nms_thr=0.7,\n",
        "        min_bbox_size=0),\n",
        "    rcnn=dict(\n",
        "        # score_thr=0.05, nms=dict(type='py_cpu_nms_poly_fast', iou_thr=0.1), max_per_img=1000)\n",
        "        score_thr = 0.05, nms = dict(type='py_cpu_nms_poly_fast', iou_thr=0.1), max_per_img = 2000)\n",
        "        # score_thr = 0.001, nms = dict(type='pesudo_nms_poly', iou_thr=0.9), max_per_img = 2000)\n",
        "        # score_thr = 0.001, nms = dict(type='py_cpu_nms_poly_fast', iou_thr=0.1), max_per_img = 2000)\n",
        "\n",
        "# soft-nms is also supported for rcnn testing\n",
        "    # e.g., nms=dict(type='soft_nms', iou_thr=0.5, min_score=0.05)\n",
        ")\n",
        "# dataset settings\n",
        "dataset_type = 'UCASAOD'\n",
        "######################################################################################################################\n",
        "# data_root = '/content/ReDet/data/dota1_1024/'\n",
        "# data_root = '/content/ReDet/data/dota_redet/'\n",
        "data_root = '/content/ReDet/data/UCAS-AOD/'\n",
        "######################################################################################################################\n",
        "img_norm_cfg = dict(\n",
        "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
        "data = dict(\n",
        "    imgs_per_gpu=2,\n",
        "    workers_per_gpu=2,\n",
        "    train=dict(\n",
        "        type=dataset_type,\n",
        "        ann_file=data_root + 'Train/mmtrain.json',\n",
        "        img_prefix=data_root + 'Train/images/',\n",
        "        img_scale=(659, 1280),\n",
        "        img_norm_cfg=img_norm_cfg,\n",
        "        size_divisor=32,\n",
        "        flip_ratio=0.5,\n",
        "        with_mask=True,\n",
        "        with_crowd=True,\n",
        "        with_label=True),\n",
        "    val=dict(\n",
        "        type=dataset_type,\n",
        "        ann_file=data_root + 'val/mmval.json',\n",
        "        img_prefix=data_root + 'val/images',\n",
        "        img_scale=(659, 1280),\n",
        "        img_norm_cfg=img_norm_cfg,\n",
        "        size_divisor=32,\n",
        "        flip_ratio=0,\n",
        "        with_mask=True,\n",
        "        with_crowd=True,\n",
        "        with_label=True),\n",
        "    test=dict(\n",
        "        type=dataset_type,\n",
        "        #############################################################################################\n",
        "        ann_file=data_root + 'Test/mmtest.json',\n",
        "        # ann_file=data_root + 'val1024/DOTA_val1024.json',\n",
        "        img_prefix=data_root + 'Test/images',\n",
        "        # img_prefix=data_root + 'val1024/images',\n",
        "        # ann_file=data_root + 'test1024_ms/DOTA_test1024_ms.json',\n",
        "        # img_prefix=data_root + 'test1024_ms/images',\n",
        "        img_scale=(659, 1280),\n",
        "        img_norm_cfg=img_norm_cfg,\n",
        "        size_divisor=32,\n",
        "        flip_ratio=0,\n",
        "        with_mask=False,\n",
        "        with_label=False,\n",
        "        test_mode=True))\n",
        "# optimizer\n",
        "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
        "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
        "# learning policy\n",
        "lr_config = dict(\n",
        "    policy='step',\n",
        "    warmup='linear',\n",
        "    warmup_iters=500,\n",
        "    warmup_ratio=1.0 / 3,\n",
        "    step=[8, 11])\n",
        "checkpoint_config = dict(interval=6)\n",
        "# yapf:disable\n",
        "log_config = dict(\n",
        "    interval=6,\n",
        "    hooks=[\n",
        "        dict(type='TextLoggerHook'),\n",
        "        dict(type='TensorboardLoggerHook')\n",
        "    ])\n",
        "# yapf:enable\n",
        "# runtime settings\n",
        "total_epochs = 12\n",
        "dist_params = dict(backend='nccl')\n",
        "log_level = 'INFO'\n",
        "work_dir = './work_dirs/faster_rcnn_RoITrans_r50_fpn_3x_UCAS_AOD'\n",
        "load_from = None\n",
        "resume_from = None\n",
        "workflow = [('train', 1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdNfXqhIkwa8"
      },
      "source": [
        "# %pycat /content/ReDet/configs/DOTA/faster_rcnn_RoITrans_r50_fpn_1x_dota.py\n",
        "# %%writefile /content/ReDet/configs/UCAS_AOD/faster_rcnn_RoITrans_r50_fpn_3x_UCAS_AOD_659.py\n",
        "##########این کانفیگ از ریپازیتوری اصلی کمک گرفته است\n",
        "\n",
        "# model settings\n",
        "model = dict(\n",
        "    type='RoITransformer',\n",
        "    pretrained='modelzoo://resnet50',\n",
        "    backbone=dict(\n",
        "        type='ResNet',\n",
        "        depth=50,\n",
        "        num_stages=4,\n",
        "        out_indices=(0, 1, 2, 3),\n",
        "        frozen_stages=1,\n",
        "        style='pytorch'),\n",
        "    neck=dict(\n",
        "        type='FPN',\n",
        "        in_channels=[256, 512, 1024, 2048],\n",
        "        out_channels=256,\n",
        "        num_outs=5),\n",
        "    rpn_head=dict(\n",
        "        type='RPNHead',\n",
        "        in_channels=256,\n",
        "        feat_channels=256,\n",
        "        anchor_scales=[8],\n",
        "        anchor_ratios=[0.5, 1.0, 2.0],\n",
        "        anchor_strides=[4, 8, 16, 32, 64],\n",
        "        target_means=[.0, .0, .0, .0],\n",
        "        target_stds=[1.0, 1.0, 1.0, 1.0],\n",
        "        loss_cls=dict(\n",
        "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
        "        loss_bbox=dict(type='SmoothL1Loss', beta=1.0 / 9.0, loss_weight=1.0)),\n",
        "    bbox_roi_extractor=dict(\n",
        "        type='SingleRoIExtractor',\n",
        "        roi_layer=dict(type='RoIAlign', out_size=7, sample_num=2),\n",
        "        out_channels=256,\n",
        "        featmap_strides=[4, 8, 16, 32]),\n",
        "    bbox_head=dict(\n",
        "        type='SharedFCBBoxHeadRbbox',\n",
        "        num_fcs=2,\n",
        "        in_channels=256,\n",
        "        fc_out_channels=1024,\n",
        "        roi_feat_size=7,\n",
        "        num_classes=3,\n",
        "        target_means=[0., 0., 0., 0., 0.],\n",
        "        target_stds=[0.1, 0.1, 0.2, 0.2, 0.1],\n",
        "        reg_class_agnostic=True,\n",
        "        with_module=False,\n",
        "        loss_cls=dict(\n",
        "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
        "        loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0)),\n",
        "    rbbox_roi_extractor=dict(\n",
        "        type='RboxSingleRoIExtractor',\n",
        "        roi_layer=dict(type='RoIAlignRotated', out_size=7, sample_num=2),\n",
        "        out_channels=256,\n",
        "        featmap_strides=[4, 8, 16, 32]),\n",
        "    rbbox_head = dict(\n",
        "        type='SharedFCBBoxHeadRbbox',\n",
        "        num_fcs=2,\n",
        "        in_channels=256,\n",
        "        fc_out_channels=1024,\n",
        "        roi_feat_size=7,\n",
        "        num_classes=3,\n",
        "        target_means=[0., 0., 0., 0., 0.],\n",
        "        target_stds=[0.05, 0.05, 0.1, 0.1, 0.05],\n",
        "        reg_class_agnostic=False,\n",
        "        loss_cls=dict(\n",
        "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
        "        loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))\n",
        "    )\n",
        "# model training and testing settings\n",
        "train_cfg = dict(\n",
        "    rpn=dict(\n",
        "        assigner=dict(\n",
        "            type='MaxIoUAssignerCy',\n",
        "            pos_iou_thr=0.7,\n",
        "            neg_iou_thr=0.3,\n",
        "            min_pos_iou=0.3,\n",
        "            ignore_iof_thr=-1),\n",
        "        sampler=dict(\n",
        "            type='RandomSampler',\n",
        "            num=256,\n",
        "            pos_fraction=0.5,\n",
        "            neg_pos_ub=-1,\n",
        "            add_gt_as_proposals=False),\n",
        "        allowed_border=0,\n",
        "        pos_weight=-1,\n",
        "        debug=False),\n",
        "    rpn_proposal=dict(\n",
        "        nms_across_levels=False,\n",
        "        nms_pre=2000,\n",
        "        nms_post=2000,\n",
        "        max_num=2000,\n",
        "        nms_thr=0.7,\n",
        "        min_bbox_size=0),\n",
        "    rcnn=[\n",
        "        dict(\n",
        "            assigner=dict(\n",
        "                type='MaxIoUAssignerCy',\n",
        "                pos_iou_thr=0.5,\n",
        "                neg_iou_thr=0.5,\n",
        "                min_pos_iou=0.5,\n",
        "                ignore_iof_thr=-1),\n",
        "            sampler=dict(\n",
        "                type='RandomSampler',\n",
        "                num=512,\n",
        "                pos_fraction=0.25,\n",
        "                neg_pos_ub=-1,\n",
        "                add_gt_as_proposals=True),\n",
        "            pos_weight=-1,\n",
        "            debug=False),\n",
        "        dict(\n",
        "            assigner=dict(\n",
        "                type='MaxIoUAssignerRbbox',\n",
        "                pos_iou_thr=0.5,\n",
        "                neg_iou_thr=0.5,\n",
        "                min_pos_iou=0.5,\n",
        "                ignore_iof_thr=-1),\n",
        "            sampler=dict(\n",
        "                type='RandomRbboxSampler',\n",
        "                num=512,\n",
        "                pos_fraction=0.25,\n",
        "                neg_pos_ub=-1,\n",
        "                add_gt_as_proposals=True),\n",
        "            pos_weight=-1,\n",
        "            debug=False)\n",
        "    ])\n",
        "test_cfg = dict(\n",
        "    rpn=dict(\n",
        "        # TODO: test nms 2000\n",
        "        nms_across_levels=False,\n",
        "        nms_pre=2000,\n",
        "        nms_post=2000,\n",
        "        max_num=2000,\n",
        "        nms_thr=0.7,\n",
        "        min_bbox_size=0),\n",
        "    rcnn=dict(\n",
        "        # score_thr=0.05, nms=dict(type='py_cpu_nms_poly_fast', iou_thr=0.1), max_per_img=1000)\n",
        "        score_thr = 0.05, nms = dict(type='py_cpu_nms_poly_fast', iou_thr=0.1), max_per_img = 2000)\n",
        "        # score_thr = 0.001, nms = dict(type='pesudo_nms_poly', iou_thr=0.9), max_per_img = 2000)\n",
        "        # score_thr = 0.001, nms = dict(type='py_cpu_nms_poly_fast', iou_thr=0.1), max_per_img = 2000)\n",
        "\n",
        "# soft-nms is also supported for rcnn testing\n",
        "    # e.g., nms=dict(type='soft_nms', iou_thr=0.5, min_score=0.05)\n",
        ")\n",
        "# dataset settings\n",
        "dataset_type = 'UCASAOD'\n",
        "######################################################################################################################\n",
        "# data_root = '/content/ReDet/data/dota1_1024/'\n",
        "# data_root = '/content/ReDet/data/dota_redet/'\n",
        "data_root = '/content/ReDet/data/UCAS_AOD659/'\n",
        "######################################################################################################################\n",
        "img_norm_cfg = dict(\n",
        "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
        "data = dict(\n",
        "    imgs_per_gpu=2,\n",
        "    workers_per_gpu=2,\n",
        "    train=dict(\n",
        "        type=dataset_type,\n",
        "        ann_file=data_root + 'trainval659/DOTA_trainval659.json',\n",
        "        img_prefix=data_root + 'trainval659/images/',\n",
        "        img_scale=(659, 659),\n",
        "        img_norm_cfg=img_norm_cfg,\n",
        "        size_divisor=32,\n",
        "        flip_ratio=0.5,\n",
        "        with_mask=True,\n",
        "        with_crowd=True,\n",
        "        with_label=True),\n",
        "    val=dict(\n",
        "        type=dataset_type,\n",
        "        ann_file=data_root + 'trainval659/DOTA_trainval659.json',\n",
        "        img_prefix=data_root + 'trainval659/images',\n",
        "        img_scale=(659, 659),\n",
        "        img_norm_cfg=img_norm_cfg,\n",
        "        size_divisor=32,\n",
        "        flip_ratio=0,\n",
        "        with_mask=True,\n",
        "        with_crowd=True,\n",
        "        with_label=True),\n",
        "    test=dict(\n",
        "        type=dataset_type,\n",
        "        #############################################################################################\n",
        "        ann_file=data_root + 'test659/DOTA_test659.json',\n",
        "        # ann_file=data_root + 'val1024/DOTA_val1024.json',\n",
        "        img_prefix=data_root + 'test659/images',\n",
        "        # img_prefix=data_root + 'val1024/images',\n",
        "        # ann_file=data_root + 'test1024_ms/DOTA_test1024_ms.json',\n",
        "        # img_prefix=data_root + 'test1024_ms/images',\n",
        "        img_scale=(659, 659),\n",
        "        img_norm_cfg=img_norm_cfg,\n",
        "        size_divisor=32,\n",
        "        flip_ratio=0,\n",
        "        with_mask=False,\n",
        "        with_label=False,\n",
        "        test_mode=True))\n",
        "# optimizer\n",
        "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
        "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
        "# learning policy\n",
        "lr_config = dict(\n",
        "    policy='step',\n",
        "    warmup='linear',\n",
        "    warmup_iters=500,\n",
        "    warmup_ratio=1.0 / 3,\n",
        "    step=[8, 11])\n",
        "checkpoint_config = dict(interval=6)\n",
        "# yapf:disable\n",
        "log_config = dict(\n",
        "    interval=6,\n",
        "    hooks=[\n",
        "        dict(type='TextLoggerHook'),\n",
        "        dict(type='TensorboardLoggerHook')\n",
        "    ])\n",
        "# yapf:enable\n",
        "# runtime settings\n",
        "total_epochs = 36\n",
        "dist_params = dict(backend='nccl')\n",
        "log_level = 'INFO'\n",
        "work_dir = './work_dirs/faster_rcnn_RoITrans_r50_fpn_3x_UCAS_AOD_659'\n",
        "load_from = None\n",
        "resume_from = None\n",
        "workflow = [('train', 1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pT6DVa5zptwp"
      },
      "source": [
        "# آموزش شبکه"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc9KlcGVRbSA"
      },
      "source": [
        "!python tools/train.py /content/AerialDetection/configs/DOTA/faster_rcnn_obb_r50_fpn_1x_dota.py --resume_from /content/AerialDetection/work_dirs/faster_rcnn_obb_r50_fpn_1x_dota/epoch_11.pth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q552hcSkPMd"
      },
      "source": [
        "!mv /content/AerialDetection/data/dota /content/drive/MyDrive/dota_dataaaaa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUHzMnZjym74"
      },
      "source": [
        "# UCAS_AOD آموزش"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fdeh1TOwyl-s"
      },
      "source": [
        "%cd /content/ReDet\n",
        "!python tools/train.py /content/ReDet/configs/UCAS_AOD/faster_rcnn_RoITrans_r50_fpn_3x_UCAS_AOD.py \\\n",
        "# --resume_from /content/ReDet/work_dirs/faster_rcnn_RoITrans_r50_fpn_3x_UCAS_AOD/epoch_6.pth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEO4EAW8k9a-"
      },
      "source": [
        "%cd /content/ReDet\n",
        "!python tools/train.py /content/ReDet/configs/UCAS_AOD/faster_rcnn_RoITrans_r50_fpn_3x_UCAS_AOD_659.py \\\n",
        "# --resume_from /content/ReDet/work_dirs/faster_rcnn_RoITrans_r50_fpn_3x_UCAS_AOD/epoch_6.pth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IqZOzLQjQ5r"
      },
      "source": [
        "# تست کردن شبکه"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHhkDYeLje_T"
      },
      "source": [
        "ReDet_re50_refpn_1x_dota1 test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-04lRL0jUwQ"
      },
      "source": [
        "!python /content/ReDet/tools/test.py /content/ReDet/configs/ReDet/ReDet_re50_refpn_1x_dota1.py  \\\n",
        "  /content/ReDet/work_dirs/pth/ReDet_re50_refpn_1x_dota1-a025e6b1.pth --out /content/ReDet/work_dirs/ReDet_re50_refpn_1x_dota1/results.pkl "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUT7OIEQw_M-"
      },
      "source": [
        "!python /content/ReDet/tools/test.py /content/ReDet/configs/ReDet/ReDet_re50_refpn_1x_dota1.py  \\\n",
        "  /content/ReDet/work_dirs/pth/ReDet_re50_refpn_1x_dota1-a025e6b1.pth --out /content/ReDet/work_dirs/ReDet_re50_refpn_1x_dota1/results.pkl "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z34WMRNTXxhh"
      },
      "source": [
        "!python /content/ReDet/tools/test.py /content/ReDet/configs/ReDet/ReDet_re50_refpn_1x_dota1.py  \\\n",
        "  /content/ReDet/work_dirs/pth/ReDet_re50_refpn_1x_dota1-a025e6b1.pth --out /content/ReDet/work_dirs/ReDet_re50_refpn_1x_dota1/valresults.pkl "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7o54deMlsoE"
      },
      "source": [
        "faster_rcnn_RoITrans_r50_fpn_1x_dota test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o7oXfislrxn"
      },
      "source": [
        "!python /content/ReDet/tools/test.py /content/ReDet/configs/DOTA/faster_rcnn_RoITrans_r50_fpn_1x_dota.py  \\\n",
        "  /content/ReDet/work_dirs/faster_rcnn_RoITrans_r50_fpn_1x_dota/epoch_12.pth --out /content/ReDet/work_dirs/faster_rcnn_RoITrans_r50_fpn_1x_dota/results.pkl "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Jxaahr4bS7J"
      },
      "source": [
        "#new-----dotanew1024\n",
        "!python /content/ReDet/tools/test.py /content/ReDet/configs/DOTA/faster_rcnn_RoITrans_r50_fpn_1x_dota.py  \\\n",
        "  /content/ReDet/work_dirs/faster_rcnn_RoITrans_r50_fpn_1x_dota/epoch_12.pth --out /content/ReDet/work_dirs/faster_rcnn_RoITrans_r50_fpn_1x_dota/results.pkl "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS5yjkgkwpsP"
      },
      "source": [
        "#val\n",
        "!python /content/ReDet/tools/test.py /content/ReDet/configs/DOTA/faster_rcnn_RoITrans_r50_fpn_1x_dota.py  \\\n",
        "  /content/ReDet/work_dirs/faster_rcnn_RoITrans_r50_fpn_1x_dota/epoch_12.pth --out /content/ReDet/work_dirs/faster_rcnn_RoITrans_r50_fpn_1x_dota/valresults.pkl "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KXGXmfkoEJm"
      },
      "source": [
        "faster_rcnn_obb_r50_fpn_1x_dota.py test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayvhovoBnemV"
      },
      "source": [
        "!python /content/ReDet/tools/test.py /content/ReDet/configs/DOTA/faster_rcnn_obb_r50_fpn_1x_dota.py  \\\n",
        "        /content/ReDet/work_dirs/faster_rcnn_obb_r50_fpn_1x_dota/epoch_12.pth --out /content/ReDet/work_dirs/faster_rcnn_obb_r50_fpn_1x_dota/results.pkl "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qW8pDLYsdHfA"
      },
      "source": [
        "#new-----dotanew1024\n",
        "!python /content/ReDet/tools/test.py /content/ReDet/configs/DOTA/faster_rcnn_obb_r50_fpn_1x_dota.py  \\\n",
        "        /content/ReDet/work_dirs/faster_rcnn_obb_r50_fpn_1x_dota/epoch_12.pth --out /content/ReDet/work_dirs/faster_rcnn_obb_r50_fpn_1x_dota/results.pkl "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKXDzUZx0jN_"
      },
      "source": [
        "#val\n",
        "!python /content/ReDet/tools/test.py /content/ReDet/configs/DOTA/faster_rcnn_obb_r50_fpn_1x_dota.py  \\\n",
        "        /content/ReDet/work_dirs/faster_rcnn_obb_r50_fpn_1x_dota/epoch_12.pth --out /content/ReDet/work_dirs/faster_rcnn_obb_r50_fpn_1x_dota/valresults.pkl "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3gn3ATB5pEU"
      },
      "source": [
        "# faster_rcnn_RoITrans_r50_fpn_3x_UCAS_AOD **testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZTThjQD5oTB"
      },
      "source": [
        "!python /content/ReDet/tools/test.py /content/ReDet/configs/UCAS_AOD/faster_rcnn_RoITrans_r50_fpn_3x_UCAS_AOD.py  \\\n",
        "  /content/ReDet/work_dirs/faster_rcnn_RoITrans_r50_fpn_3x_UCAS_AOD/epoch_36.pth --out /content/ReDet/work_dirs/faster_rcnn_RoITrans_r50_fpn_3x_UCAS_AOD/results.pkl "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYiy71Ny-_jS"
      },
      "source": [
        "# **HSRC2016** ReDet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSUvBEn--_Q5"
      },
      "source": [
        "# generate results\n",
        "!python /content/ReDet/tools/test.py /content/ReDet/configs/ReDet/ReDet_re50_refpn_3x_hrsc2016.py \\\n",
        "    /content/ReDet/work_dirs/ReDet_re50_refpn_3x_hrsc2016/ReDet_re50_refpn_3x_hrsc2016-d1b4bd29.pth  --out /content/ReDet/work_dirs/ReDet_re50_refpn_3x_hrsc2016/results.pkl\n",
        "\n",
        "# evaluation\n",
        "# remeber to modify the results path in hrsc2016_evaluation.py\n",
        "# !python /content/ReDet/DOTA_devkit/hrsc2016_evaluation.py    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FubiGN-XM4pJ"
      },
      "source": [
        "/content/ReDet/DOTA_devkit/hrsc2016_evaluation.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSwoArYQMyDd"
      },
      "source": [
        "%%writefile /content/ReDet/DOTA_devkit/hrsc2016_evaluation.py\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# dota_evaluation_task1\n",
        "# Licensed under The MIT License [see LICENSE for details]\n",
        "# Written by Jian Ding, based on code from Bharath Hariharan\n",
        "# --------------------------------------------------------\n",
        "\n",
        "\"\"\"\n",
        "    To use the code, users should to config detpath, annopath and imagesetfile\n",
        "    detpath is the path for 15 result files, for the format, you can refer to \"http://captain.whu.edu.cn/DOTAweb/tasks.html\"\n",
        "    search for PATH_TO_BE_CONFIGURED to config the paths\n",
        "    Note, the evaluation is on the large scale images\n",
        "\"\"\"\n",
        "import xml.etree.ElementTree as ET\n",
        "import os\n",
        "#import cPickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import polyiou\n",
        "from functools import partial\n",
        "\n",
        "def parse_gt(filename):\n",
        "    \"\"\"\n",
        "    :param filename: ground truth file to parse\n",
        "    :return: all instances in a picture\n",
        "    \"\"\"\n",
        "    objects = []\n",
        "    with  open(filename, 'r') as f:\n",
        "        while True:\n",
        "            line = f.readline()\n",
        "            if line:\n",
        "                splitlines = line.strip().split(' ')\n",
        "                object_struct = {}\n",
        "                if (len(splitlines) < 9):\n",
        "                    continue\n",
        "                object_struct['name'] = splitlines[8]\n",
        "\n",
        "                if (len(splitlines) == 9):\n",
        "                    object_struct['difficult'] = 0\n",
        "                elif (len(splitlines) == 10):\n",
        "                    object_struct['difficult'] = int(splitlines[9])\n",
        "                object_struct['bbox'] = [float(splitlines[0]),\n",
        "                                         float(splitlines[1]),\n",
        "                                         float(splitlines[2]),\n",
        "                                         float(splitlines[3]),\n",
        "                                         float(splitlines[4]),\n",
        "                                         float(splitlines[5]),\n",
        "                                         float(splitlines[6]),\n",
        "                                         float(splitlines[7])]\n",
        "                objects.append(object_struct)\n",
        "            else:\n",
        "                break\n",
        "    return objects\n",
        "def voc_ap(rec, prec, use_07_metric=False):\n",
        "    \"\"\" ap = voc_ap(rec, prec, [use_07_metric])\n",
        "    Compute VOC AP given precision and recall.\n",
        "    If use_07_metric is true, uses the\n",
        "    VOC 07 11 point method (default:False).\n",
        "    \"\"\"\n",
        "    if use_07_metric:\n",
        "        # 11 point metric\n",
        "        ap = 0.\n",
        "        for t in np.arange(0., 1.1, 0.1):\n",
        "            if np.sum(rec >= t) == 0:\n",
        "                p = 0\n",
        "            else:\n",
        "                p = np.max(prec[rec >= t])\n",
        "            ap = ap + p / 11.\n",
        "    else:\n",
        "        # correct AP calculation\n",
        "        # first append sentinel values at the end\n",
        "        mrec = np.concatenate(([0.], rec, [1.]))\n",
        "        mpre = np.concatenate(([0.], prec, [0.]))\n",
        "\n",
        "        # compute the precision envelope\n",
        "        for i in range(mpre.size - 1, 0, -1):\n",
        "            mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
        "\n",
        "        # to calculate area under PR curve, look for points\n",
        "        # where X axis (recall) changes value\n",
        "        i = np.where(mrec[1:] != mrec[:-1])[0]\n",
        "\n",
        "        # and sum (\\Delta recall) * prec\n",
        "        ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
        "    return ap\n",
        "\n",
        "\n",
        "def voc_eval(detpath,\n",
        "             annopath,\n",
        "             imagesetfile,\n",
        "             classname,\n",
        "            # cachedir,\n",
        "             ovthresh=0.5,\n",
        "             use_07_metric=False):\n",
        "    \"\"\"rec, prec, ap = voc_eval(detpath,\n",
        "                                annopath,\n",
        "                                imagesetfile,\n",
        "                                classname,\n",
        "                                [ovthresh],\n",
        "                                [use_07_metric])\n",
        "    Top level function that does the PASCAL VOC evaluation.\n",
        "    detpath: Path to detections\n",
        "        detpath.format(classname) should produce the detection results file.\n",
        "    annopath: Path to annotations\n",
        "        annopath.format(imagename) should be the xml annotations file.\n",
        "    imagesetfile: Text file containing the list of images, one image per line.\n",
        "    classname: Category name (duh)\n",
        "    cachedir: Directory for caching the annotations\n",
        "    [ovthresh]: Overlap threshold (default = 0.5)\n",
        "    [use_07_metric]: Whether to use VOC07's 11 point AP computation\n",
        "        (default False)\n",
        "    \"\"\"\n",
        "    # assumes detections are in detpath.format(classname)\n",
        "    # assumes annotations are in annopath.format(imagename)\n",
        "    # assumes imagesetfile is a text file with each line an image name\n",
        "    # cachedir caches the annotations in a pickle file\n",
        "\n",
        "    # first load gt\n",
        "    #if not os.path.isdir(cachedir):\n",
        "     #   os.mkdir(cachedir)\n",
        "    #cachefile = os.path.join(cachedir, 'annots.pkl')\n",
        "    # read list of images\n",
        "    with open(imagesetfile, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    imagenames = [x.strip() for x in lines]\n",
        "    #print('imagenames: ', imagenames)\n",
        "    #if not os.path.isfile(cachefile):\n",
        "        # load annots\n",
        "    recs = {}\n",
        "    for i, imagename in enumerate(imagenames):\n",
        "        #print('parse_files name: ', annopath.format(imagename))\n",
        "        recs[imagename] = parse_gt(annopath.format(imagename))\n",
        "        #if i % 100 == 0:\n",
        "         #   print ('Reading annotation for {:d}/{:d}'.format(\n",
        "          #      i + 1, len(imagenames)) )\n",
        "        # save\n",
        "        #print ('Saving cached annotations to {:s}'.format(cachefile))\n",
        "        #with open(cachefile, 'w') as f:\n",
        "         #   cPickle.dump(recs, f)\n",
        "    #else:\n",
        "        # load\n",
        "        #with open(cachefile, 'r') as f:\n",
        "         #   recs = cPickle.load(f)\n",
        "\n",
        "    # extract gt objects for this class\n",
        "    class_recs = {}\n",
        "    npos = 0\n",
        "    for imagename in imagenames:\n",
        "        R = [obj for obj in recs[imagename] if obj['name'] == classname]\n",
        "        bbox = np.array([x['bbox'] for x in R])\n",
        "        difficult = np.array([x['difficult'] for x in R]).astype(np.bool)\n",
        "        det = [False] * len(R)\n",
        "        npos = npos + sum(~difficult)\n",
        "        class_recs[imagename] = {'bbox': bbox,\n",
        "                                 'difficult': difficult,\n",
        "                                 'det': det}\n",
        "\n",
        "    # read dets from Task1* files\n",
        "    detfile = detpath.format(classname)\n",
        "    with open(detfile, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    splitlines = [x.strip().split(' ') for x in lines]\n",
        "    image_ids = [x[0] for x in splitlines]\n",
        "    confidence = np.array([float(x[1]) for x in splitlines])\n",
        "\n",
        "    #print('check confidence: ', confidence)\n",
        "\n",
        "    BB = np.array([[float(z) for z in x[2:]] for x in splitlines])\n",
        "\n",
        "    # sort by confidence\n",
        "    sorted_ind = np.argsort(-confidence)\n",
        "    sorted_scores = np.sort(-confidence)\n",
        "\n",
        "    #print('check sorted_scores: ', sorted_scores)\n",
        "    #print('check sorted_ind: ', sorted_ind)\n",
        "\n",
        "    ## note the usage only in numpy not for list\n",
        "    BB = BB[sorted_ind, :]\n",
        "    image_ids = [image_ids[x] for x in sorted_ind]\n",
        "    #print('check imge_ids: ', image_ids)\n",
        "    #print('imge_ids len:', len(image_ids))\n",
        "    # go down dets and mark TPs and FPs\n",
        "    nd = len(image_ids)\n",
        "    tp = np.zeros(nd)\n",
        "    fp = np.zeros(nd)\n",
        "    for d in range(nd):\n",
        "      ##############################################################################################################\n",
        "        filename, file_extension = os.path.splitext(image_ids[d])\n",
        "        R = class_recs[ filename]\n",
        "        # R = class_recs[image_ids[d]]##############################################################################\n",
        "\n",
        "        bb = BB[d, :].astype(float)\n",
        "        ovmax = -np.inf\n",
        "        BBGT = R['bbox'].astype(float)\n",
        "\n",
        "        ## compute det bb with each BBGT\n",
        "\n",
        "        if BBGT.size > 0:\n",
        "            # compute overlaps\n",
        "            # intersection\n",
        "\n",
        "            # 1. calculate the overlaps between hbbs, if the iou between hbbs are 0, the iou between obbs are 0, too.\n",
        "            # pdb.set_trace()\n",
        "            BBGT_xmin =  np.min(BBGT[:, 0::2], axis=1)\n",
        "            BBGT_ymin = np.min(BBGT[:, 1::2], axis=1)\n",
        "            BBGT_xmax = np.max(BBGT[:, 0::2], axis=1)\n",
        "            BBGT_ymax = np.max(BBGT[:, 1::2], axis=1)\n",
        "            bb_xmin = np.min(bb[0::2])\n",
        "            bb_ymin = np.min(bb[1::2])\n",
        "            bb_xmax = np.max(bb[0::2])\n",
        "            bb_ymax = np.max(bb[1::2])\n",
        "\n",
        "            ixmin = np.maximum(BBGT_xmin, bb_xmin)\n",
        "            iymin = np.maximum(BBGT_ymin, bb_ymin)\n",
        "            ixmax = np.minimum(BBGT_xmax, bb_xmax)\n",
        "            iymax = np.minimum(BBGT_ymax, bb_ymax)\n",
        "            iw = np.maximum(ixmax - ixmin + 1., 0.)\n",
        "            ih = np.maximum(iymax - iymin + 1., 0.)\n",
        "            inters = iw * ih\n",
        "\n",
        "            # union\n",
        "            uni = ((bb_xmax - bb_xmin + 1.) * (bb_ymax - bb_ymin + 1.) +\n",
        "                   (BBGT_xmax - BBGT_xmin + 1.) *\n",
        "                   (BBGT_ymax - BBGT_ymin + 1.) - inters)\n",
        "\n",
        "            overlaps = inters / uni\n",
        "\n",
        "            BBGT_keep_mask = overlaps > 0\n",
        "            BBGT_keep = BBGT[BBGT_keep_mask, :]\n",
        "            BBGT_keep_index = np.where(overlaps > 0)[0]\n",
        "            # pdb.set_trace()\n",
        "            def calcoverlaps(BBGT_keep, bb):\n",
        "                overlaps = []\n",
        "                for index, GT in enumerate(BBGT_keep):\n",
        "\n",
        "                    overlap = polyiou.iou_poly(polyiou.VectorDouble(BBGT_keep[index]), polyiou.VectorDouble(bb))\n",
        "                    overlaps.append(overlap)\n",
        "                return overlaps\n",
        "            if len(BBGT_keep) > 0:\n",
        "                overlaps = calcoverlaps(BBGT_keep, bb)\n",
        "\n",
        "                ovmax = np.max(overlaps)\n",
        "                jmax = np.argmax(overlaps)\n",
        "                # pdb.set_trace()\n",
        "                jmax = BBGT_keep_index[jmax]\n",
        "\n",
        "        if ovmax > ovthresh:\n",
        "            if not R['difficult'][jmax]:\n",
        "                if not R['det'][jmax]:\n",
        "                    tp[d] = 1.\n",
        "                    R['det'][jmax] = 1\n",
        "                else:\n",
        "                    fp[d] = 1.\n",
        "        else:\n",
        "            fp[d] = 1.\n",
        "\n",
        "    # compute precision recall\n",
        "\n",
        "    print('check fp:', fp)\n",
        "    print('check tp', tp)\n",
        "\n",
        "\n",
        "    print('npos num:', npos)\n",
        "    fp = np.cumsum(fp)\n",
        "    tp = np.cumsum(tp)\n",
        "\n",
        "    rec = tp / float(npos)\n",
        "    # avoid divide by zero in case the first detection matches a difficult\n",
        "    # ground truth\n",
        "    prec = tp / np.maximum(tp + fp, np.finfo(np.float64).eps)\n",
        "    ap = voc_ap(rec, prec, use_07_metric)\n",
        "\n",
        "    return rec, prec, ap\n",
        "\n",
        "def main():\n",
        "    \n",
        "    detpath = r'/content/ReDet/work_dirs/ReDet_re50_refpn_3x_hrsc2016/Task1_{:s}.txt'\n",
        "    annopath = r'/content/ReDet/data/HRSC2016/Test/labelTxt/{:s}.txt' # change the directory to the path of val/labelTxt, if you want to do evaluation on the valset\n",
        "    imagesetfile = r'/content/ReDet/data/HRSC2016/Test/test.txt'\n",
        "\n",
        "\n",
        "    # For HRSC2016\n",
        "    classnames = ['ship']\n",
        "    classaps = []\n",
        "    map = 0\n",
        "    for classname in classnames:\n",
        "        print('classname:', classname)\n",
        "        rec, prec, ap = voc_eval(detpath,\n",
        "             annopath,\n",
        "             imagesetfile,\n",
        "             classname,\n",
        "             ovthresh=0.5,\n",
        "             use_07_metric=True)\n",
        "        map = map + ap\n",
        "        #print('rec: ', rec, 'prec: ', prec, 'ap: ', ap)\n",
        "        print('ap: ', ap)\n",
        "        classaps.append(ap)\n",
        "\n",
        "        # umcomment to show p-r curve of each category\n",
        "        # plt.figure(figsize=(8,4))\n",
        "        # plt.xlabel('recall')\n",
        "        # plt.ylabel('precision')\n",
        "        # plt.plot(rec, prec)\n",
        "       # plt.show()\n",
        "    map = map/len(classnames)\n",
        "    print('map:', map)\n",
        "    classaps = 100*np.array(classaps)\n",
        "    print('classaps: ', classaps)\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhM4KhSeBaar"
      },
      "source": [
        "# evaluation\n",
        "# remeber to modify the results path in hrsc2016_evaluation.py\n",
        "!python /content/ReDet/DOTA_devkit/hrsc2016_evaluation.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pvq6acOhYLh"
      },
      "source": [
        "# برای پارس کردن فایل **ولیدیشن** کد زیر اجرا شود"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIfe_MCUaMSp"
      },
      "source": [
        "# %pycat /content/AerialDetection/tools/parse_results.py\n",
        "%%writefile /content/ReDet/tools/parse_results.py\n",
        "\n",
        "from __future__ import division\n",
        "\n",
        "import argparse\n",
        "import os.path as osp\n",
        "import shutil\n",
        "import tempfile\n",
        "\n",
        "import mmcv\n",
        "from mmdet.apis import init_dist\n",
        "from mmdet.core import results2json, coco_eval, \\\n",
        "    HBBSeg2Comp4, OBBDet2Comp4, OBBDetComp4, \\\n",
        "    HBBOBB2Comp4, HBBDet2Comp4\n",
        "\n",
        "import argparse\n",
        "\n",
        "from mmdet import __version__\n",
        "from mmdet.datasets import get_dataset\n",
        "from mmdet.apis import (train_detector, init_dist, get_root_logger,\n",
        "                        set_random_seed)\n",
        "from mmdet.models import build_detector\n",
        "import torch\n",
        "import json\n",
        "from mmcv import Config\n",
        "import sys\n",
        "# sys.path.insert(0, '../')\n",
        "# import DOTA_devkit.ResultMerge_multi_process as RM\n",
        "from DOTA_devkit.ResultMerge_multi_process import *\n",
        "# import pdb; pdb.set_trace()\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser(description='Train a detector')\n",
        "    parser.add_argument('--config', default='configs/DOTA/faster_rcnn_r101_fpn_1x_dota2_v3_RoITrans_v5.py')\n",
        "    parser.add_argument('--type', default=r'HBB',\n",
        "                        help='parse type of detector')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    return args\n",
        "\n",
        "def OBB2HBB(srcpath, dstpath):\n",
        "    filenames = util.GetFileFromThisRootDir(srcpath)\n",
        "    if not os.path.exists(dstpath):\n",
        "        os.makedirs(dstpath)\n",
        "    for file in filenames:\n",
        "        with open(file, 'r') as f_in:\n",
        "            with open(os.path.join(dstpath, os.path.basename(os.path.splitext(file)[0]) + '.txt'), 'w') as f_out:\n",
        "                lines = f_in.readlines()\n",
        "                splitlines = [x.strip().split() for x in lines]\n",
        "                for index, splitline in enumerate(splitlines):\n",
        "                    imgname = splitline[0]\n",
        "                    score = splitline[1]\n",
        "                    poly = splitline[2:]\n",
        "                    poly = list(map(float, poly))\n",
        "                    xmin, xmax, ymin, ymax = min(poly[0::2]), max(poly[0::2]), min(poly[1::2]), max(poly[1::2])\n",
        "                    rec_poly = [xmin, ymin, xmax, ymax]\n",
        "                    outline = imgname + ' ' + score + ' ' + ' '.join(map(str, rec_poly))\n",
        "                    if index != (len(splitlines) - 1):\n",
        "                        outline = outline + '\\n'\n",
        "                    f_out.write(outline)\n",
        "\n",
        "def parse_results(config_file, resultfile, dstpath, type):\n",
        "    cfg = Config.fromfile(config_file)\n",
        "\n",
        "    data_test = cfg.data['test']\n",
        "    dataset = get_dataset(data_test)\n",
        "    outputs = mmcv.load(resultfile)\n",
        "    if type == 'OBB':\n",
        "        #  dota1 has tested\n",
        "        \n",
        "        obb_results_dict = OBBDetComp4(dataset, outputs)\n",
        "        current_thresh = 0.1\n",
        "    elif type == 'HBB':\n",
        "        # dota1 has tested\n",
        "        hbb_results_dict = HBBDet2Comp4(dataset, outputs)\n",
        "    elif type == 'HBBOBB':\n",
        "        # dota1 has tested\n",
        "        # dota2\n",
        "        hbb_results_dict, obb_results_dict = HBBOBB2Comp4(dataset, outputs)\n",
        "        current_thresh = 0.3\n",
        "    elif type == 'Mask':\n",
        "        # TODO: dota1 did not pass\n",
        "        # dota2, hbb has passed, obb has passed\n",
        "        hbb_results_dict, obb_results_dict = HBBSeg2Comp4(dataset, outputs)\n",
        "        current_thresh = 0.3\n",
        "\n",
        "    dataset_type = cfg.dataset_type\n",
        "\n",
        "    if 'obb_results_dict' in vars():\n",
        "        if not os.path.exists(os.path.join(dstpath, 'Task1_results')):\n",
        "            os.makedirs(os.path.join(dstpath, 'Task1_results'))\n",
        "\n",
        "        for cls in obb_results_dict:\n",
        "            with open(os.path.join(dstpath, 'Task1_results', cls + '.txt'), 'w') as obb_f_out:\n",
        "                for index, outline in enumerate(obb_results_dict[cls]):\n",
        "                    if index != (len(obb_results_dict[cls]) - 1):\n",
        "                        obb_f_out.write(outline + '\\n')\n",
        "                    else:\n",
        "                        obb_f_out.write(outline)\n",
        "\n",
        "        if not os.path.exists(os.path.join(dstpath, 'Task1_results_nms')):\n",
        "            os.makedirs(os.path.join(dstpath, 'Task1_results_nms'))\n",
        "\n",
        "        mergebypoly_multiprocess(os.path.join(dstpath, 'Task1_results'),\n",
        "                                 os.path.join(dstpath, 'Task1_results_nms'), nms_type=r'py_cpu_nms_poly_fast', o_thresh=current_thresh)\n",
        "\n",
        "        OBB2HBB(os.path.join(dstpath, 'Task1_results_nms'),\n",
        "                         os.path.join(dstpath, 'Transed_Task2_results_nms'))\n",
        "\n",
        "    if 'hbb_results_dict' in vars():\n",
        "        if not os.path.exists(os.path.join(dstpath, 'Task2_results')):\n",
        "            os.makedirs(os.path.join(dstpath, 'Task2_results'))\n",
        "        for cls in hbb_results_dict:\n",
        "            with open(os.path.join(dstpath, 'Task2_results', cls + '.txt'), 'w') as f_out:\n",
        "                for index, outline in enumerate(hbb_results_dict[cls]):\n",
        "                    if index != (len(hbb_results_dict[cls]) - 1):\n",
        "                        f_out.write(outline + '\\n')\n",
        "                    else:\n",
        "                        f_out.write(outline)\n",
        "\n",
        "        if not os.path.exists(os.path.join(dstpath, 'Task2_results_nms')):\n",
        "            os.makedirs(os.path.join(dstpath, 'Task2_results_nms'))\n",
        "        mergebyrec(os.path.join(dstpath, 'Task2_results'),\n",
        "            os.path.join(dstpath, 'Task2_results_nms'))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    args = parse_args()\n",
        "    config_file = args.config\n",
        "    config_name = os.path.splitext(os.path.basename(config_file))[0]\n",
        "\n",
        "    ######################################################################################/content/AerialDetection/work_dirs\n",
        "    # pkl_file = os.path.join('/content/ReDet/work_dirs', config_name, 'results.pkl')\n",
        "    pkl_file = os.path.join('/content/ReDet/work_dirs', config_name, 'valresults.pkl')\n",
        "    output_path = os.path.join('/content/ReDet/work_dirs', config_name)\n",
        "    type = args.type\n",
        "    parse_results(config_file, pkl_file, output_path, type)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6orwO2Vuo9JY"
      },
      "source": [
        "# به کمک دستورات زیر از فایل تولید شده‌ی سریالایز شده سه فلدر پارس شده دریافت می‌شود"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_mUnHmGRZfz"
      },
      "source": [
        "!python /content/ReDet/tools/parse_results.py --config /content/ReDet/configs/UCAS_AOD/faster_rcnn_RoITrans_r50_fpn_3x_UCAS_AOD.py --type OBB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRIjpHiopbE9"
      },
      "source": [
        "باید دانلود شده زیپ شده و آپلود شود Task1_results_nms برای ارزیابی تسک اول فایل "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72VgnGJBbHrA"
      },
      "source": [
        "#!tar -cvf '/content/ReDet/work_dirs/ReDet_re50_refpn_1x_dota1/Task1_results_nms.tar' '/content/ReDet/work_dirs/ReDet_re50_refpn_1x_dota1/Task1_results_nms'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8IWPL1OxRTs"
      },
      "source": [
        "# ارزیابی val"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrwZ2aR3zFuE"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "os.chdir(r'/content/ReDet/data/dota/val/images')\n",
        "# myFiles = glob.glob('*.bmp')\n",
        "%ls -1 | sed 's/\\.png//g' > ./testset.txt\n",
        "# print(myFiles)\n",
        "!mv '/content/ReDet/data/dota/val/images/testset.txt' '/content/ReDet/data/dota/val'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI9wqC_RxuNn"
      },
      "source": [
        "%%writefile /content/ReDet/DOTA_devkit/dota_evaluation_task1.py\n",
        "\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sys\n",
        "sys.path.insert(1,os.path.dirname(__file__))\n",
        "import polyiou\n",
        "import argparse\n",
        "\n",
        "\n",
        "def parse_gt(filename):\n",
        "    \"\"\"\n",
        "    :param filename: ground truth file to parse\n",
        "    :return: all instances in a picture\n",
        "    \"\"\"\n",
        "    objects = []\n",
        "    with open(filename, 'r') as f:\n",
        "        while True:\n",
        "            line = f.readline()\n",
        "            if line:\n",
        "                splitlines = line.strip().split(' ')\n",
        "                object_struct = {}\n",
        "                if (len(splitlines) < 9):\n",
        "                    continue\n",
        "                object_struct['name'] = splitlines[8]\n",
        "\n",
        "                if (len(splitlines) == 9):\n",
        "                    object_struct['difficult'] = 0\n",
        "                elif (len(splitlines) == 10):\n",
        "                    object_struct['difficult'] = int(splitlines[9])\n",
        "                object_struct['bbox'] = [float(splitlines[0]),\n",
        "                                         float(splitlines[1]),\n",
        "                                         float(splitlines[2]),\n",
        "                                         float(splitlines[3]),\n",
        "                                         float(splitlines[4]),\n",
        "                                         float(splitlines[5]),\n",
        "                                         float(splitlines[6]),\n",
        "                                         float(splitlines[7])]\n",
        "                objects.append(object_struct)\n",
        "            else:\n",
        "                break\n",
        "    return objects\n",
        "\n",
        "\n",
        "def voc_ap(rec, prec, use_07_metric=False):\n",
        "    \"\"\" ap = voc_ap(rec, prec, [use_07_metric])\n",
        "    Compute VOC AP given precision and recall.\n",
        "    If use_07_metric is true, uses the\n",
        "    VOC 07 11 point method (default:False).\n",
        "    \"\"\"\n",
        "    if use_07_metric:\n",
        "        # 11 point metric\n",
        "        ap = 0.\n",
        "        for t in np.arange(0., 1.1, 0.1):\n",
        "            if np.sum(rec >= t) == 0:\n",
        "                p = 0\n",
        "            else:\n",
        "                p = np.max(prec[rec >= t])\n",
        "            ap = ap + p / 11.\n",
        "    else:\n",
        "        # correct AP calculation\n",
        "        # first append sentinel values at the end\n",
        "        mrec = np.concatenate(([0.], rec, [1.]))\n",
        "        mpre = np.concatenate(([0.], prec, [0.]))\n",
        "\n",
        "        # compute the precision envelope\n",
        "        for i in range(mpre.size - 1, 0, -1):\n",
        "            mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
        "\n",
        "        # to calculate area under PR curve, look for points\n",
        "        # where X axis (recall) changes value\n",
        "        i = np.where(mrec[1:] != mrec[:-1])[0]\n",
        "\n",
        "        # and sum (\\Delta recall) * prec\n",
        "        ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
        "    return ap\n",
        "\n",
        "\n",
        "def voc_eval(detpath,\n",
        "             annopath,\n",
        "             imagesetfile,\n",
        "             classname,\n",
        "             # cachedir,\n",
        "             ovthresh=0.5,\n",
        "             use_07_metric=False):\n",
        "    \"\"\"rec, prec, ap = voc_eval(detpath,\n",
        "                                annopath,\n",
        "                                imagesetfile,\n",
        "                                classname,\n",
        "                                [ovthresh],\n",
        "                                [use_07_metric])\n",
        "    Top level function that does the PASCAL VOC evaluation.\n",
        "    detpath: Path to detections\n",
        "        detpath.format(classname) should produce the detection results file.\n",
        "    annopath: Path to annotations\n",
        "        annopath.format(imagename) should be the xml annotations file.\n",
        "    imagesetfile: Text file containing the list of images, one image per line.\n",
        "    classname: Category name (duh)\n",
        "    cachedir: Directory for caching the annotations\n",
        "    [ovthresh]: Overlap threshold (default = 0.5)\n",
        "    [use_07_metric]: Whether to use VOC07's 11 point AP computation\n",
        "        (default False)\n",
        "    \"\"\"\n",
        "    # assumes detections are in detpath.format(classname)\n",
        "    # assumes annotations are in annopath.format(imagename)\n",
        "    # assumes imagesetfile is a text file with each line an image name\n",
        "    # cachedir caches the annotations in a pickle file\n",
        "\n",
        "    # read list of images\n",
        "    with open(imagesetfile, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    imagenames = [x.strip() for x in lines]\n",
        "\n",
        "    recs = {}\n",
        "    for i, imagename in enumerate(imagenames):\n",
        "      ##############################################################################################################\n",
        "        # print('parse_files name: ', annopath.format(imagename))\n",
        "        recs[imagename] = parse_gt(annopath.format(imagename))\n",
        "\n",
        "    # extract gt objects for this class\n",
        "    class_recs = {}\n",
        "    npos = 0\n",
        "    for imagename in imagenames:\n",
        "        R = [obj for obj in recs[imagename] if obj['name'] == classname]\n",
        "        bbox = np.array([x['bbox'] for x in R])\n",
        "        difficult = np.array([x['difficult'] for x in R]).astype(np.bool)\n",
        "        det = [False] * len(R)\n",
        "        npos = npos + sum(~difficult)\n",
        "        class_recs[imagename] = {'bbox': bbox,\n",
        "                                 'difficult': difficult,\n",
        "                                 'det': det}\n",
        "\n",
        "    # read dets from Task1* files\n",
        "    detfile = detpath.format(classname)\n",
        "    with open(detfile, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    splitlines = [x.strip().split(' ') for x in lines]\n",
        "    image_ids = [x[0] for x in splitlines]\n",
        "    confidence = np.array([float(x[1]) for x in splitlines])\n",
        "\n",
        "    BB = np.array([[float(z) for z in x[2:]] for x in splitlines])\n",
        "\n",
        "    # sort by confidence\n",
        "    sorted_ind = np.argsort(-confidence)\n",
        "    sorted_scores = np.sort(-confidence)\n",
        "\n",
        "    # note the usage only in numpy not for list\n",
        "    BB = BB[sorted_ind, :]\n",
        "    image_ids = [image_ids[x] for x in sorted_ind]\n",
        "    # go down dets and mark TPs and FPs\n",
        "    nd = len(image_ids)\n",
        "    tp = np.zeros(nd)\n",
        "    fp = np.zeros(nd)\n",
        "    for d in range(nd):\n",
        "        R = class_recs[image_ids[d]]\n",
        "        bb = BB[d, :].astype(float)\n",
        "        ovmax = -np.inf\n",
        "        BBGT = R['bbox'].astype(float)\n",
        "\n",
        "        # compute det bb with each BBGT\n",
        "        if BBGT.size > 0:\n",
        "            # compute overlaps\n",
        "            # intersection\n",
        "\n",
        "            # 1. calculate the overlaps between hbbs, if the iou between hbbs are 0, the iou between obbs are 0, too.\n",
        "            BBGT_xmin = np.min(BBGT[:, 0::2], axis=1)\n",
        "            BBGT_ymin = np.min(BBGT[:, 1::2], axis=1)\n",
        "            BBGT_xmax = np.max(BBGT[:, 0::2], axis=1)\n",
        "            BBGT_ymax = np.max(BBGT[:, 1::2], axis=1)\n",
        "            bb_xmin = np.min(bb[0::2])\n",
        "            bb_ymin = np.min(bb[1::2])\n",
        "            bb_xmax = np.max(bb[0::2])\n",
        "            bb_ymax = np.max(bb[1::2])\n",
        "\n",
        "            ixmin = np.maximum(BBGT_xmin, bb_xmin)\n",
        "            iymin = np.maximum(BBGT_ymin, bb_ymin)\n",
        "            ixmax = np.minimum(BBGT_xmax, bb_xmax)\n",
        "            iymax = np.minimum(BBGT_ymax, bb_ymax)\n",
        "            iw = np.maximum(ixmax - ixmin + 1., 0.)\n",
        "            ih = np.maximum(iymax - iymin + 1., 0.)\n",
        "            inters = iw * ih\n",
        "\n",
        "            # union\n",
        "            uni = ((bb_xmax - bb_xmin + 1.) * (bb_ymax - bb_ymin + 1.) +\n",
        "                   (BBGT_xmax - BBGT_xmin + 1.) *\n",
        "                   (BBGT_ymax - BBGT_ymin + 1.) - inters)\n",
        "\n",
        "            overlaps = inters / uni\n",
        "\n",
        "            BBGT_keep_mask = overlaps > 0\n",
        "            BBGT_keep = BBGT[BBGT_keep_mask, :]\n",
        "            BBGT_keep_index = np.where(overlaps > 0)[0]\n",
        "\n",
        "            def calcoverlaps(BBGT_keep, bb):\n",
        "                overlaps = []\n",
        "                for index, GT in enumerate(BBGT_keep):\n",
        "\n",
        "                    overlap = polyiou.iou_poly(polyiou.VectorDouble(\n",
        "                        BBGT_keep[index]), polyiou.VectorDouble(bb))\n",
        "                    overlaps.append(overlap)\n",
        "                return overlaps\n",
        "            if len(BBGT_keep) > 0:\n",
        "                overlaps = calcoverlaps(BBGT_keep, bb)\n",
        "\n",
        "                ovmax = np.max(overlaps)\n",
        "                jmax = np.argmax(overlaps)\n",
        "                # pdb.set_trace()\n",
        "                jmax = BBGT_keep_index[jmax]\n",
        "\n",
        "        if ovmax > ovthresh:\n",
        "            if not R['difficult'][jmax]:\n",
        "                if not R['det'][jmax]:\n",
        "                    tp[d] = 1.\n",
        "                    R['det'][jmax] = 1\n",
        "                else:\n",
        "                    fp[d] = 1.\n",
        "        else:\n",
        "            fp[d] = 1.\n",
        "\n",
        "    # compute precision recall\n",
        "\n",
        "    print('check fp:', fp)\n",
        "    print('check tp', tp)\n",
        "\n",
        "    print('npos num:', npos)\n",
        "    fp = np.cumsum(fp)\n",
        "    tp = np.cumsum(tp)\n",
        "\n",
        "    rec = tp / float(npos)\n",
        "    # avoid divide by zero in case the first detection matches a difficult\n",
        "    # ground truth\n",
        "    prec = tp / np.maximum(tp + fp, np.finfo(np.float64).eps)\n",
        "    ap = voc_ap(rec, prec, use_07_metric)\n",
        "\n",
        "    return rec, prec, ap\n",
        "\n",
        "\n",
        "def dota_task1_eval(work_dir, det_dir):\n",
        "    detpath = os.path.join(det_dir, r'Task1_{:s}.txt')\n",
        "    annopath = r'data/dota/test/OrientlabelTxt-utf-8/{:s}.txt'\n",
        "    imagesetfile = r'data/dota/test/testset.txt'\n",
        "    # For DOTA-v1.0\n",
        "    classnames = ['plane', 'baseball-diamond', 'bridge', 'ground-track-field', 'small-vehicle', 'large-vehicle', 'ship', 'tennis-court',\n",
        "                  'basketball-court', 'storage-tank',  'soccer-ball-field', 'roundabout', 'harbor', 'swimming-pool', 'helicopter']\n",
        "    classaps = []\n",
        "    map = 0\n",
        "    for classname in classnames:\n",
        "        print('classname:', classname)\n",
        "        rec, prec, ap = voc_eval(detpath,\n",
        "                                 annopath,\n",
        "                                 imagesetfile,\n",
        "                                 classname,\n",
        "                                 ovthresh=0.5,\n",
        "                                 use_07_metric=True)\n",
        "        map = map + ap\n",
        "        #print('rec: ', rec, 'prec: ', prec, 'ap: ', ap)\n",
        "        print('ap: ', ap)\n",
        "        classaps.append(ap)\n",
        "    map = map/len(classnames)\n",
        "    print('map:', map)\n",
        "    classaps = 100*np.array(classaps)\n",
        "    print('classaps: ', classaps)\n",
        "    # writing results to txt file\n",
        "    with open(os.path.join(work_dir, 'Task1_results.txt'), 'w') as f:\n",
        "        out_str = ''\n",
        "        out_str += 'mAP:'+str(map)+'\\n'\n",
        "        out_str += 'APs:\\n'\n",
        "        out_str += ' '.join([str(ap)for ap in classaps.tolist()])\n",
        "        f.write(out_str)\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--work_dir',default='')\n",
        "    return parser.parse_args()\n",
        "\n",
        "def main():\n",
        "    args = parse_args()\n",
        "    # detpath = os.path.join(args.work_dir,'Task1_results_nms/Task1_{:s}.txt')\n",
        "    detpath = os.path.join(args.work_dir,'Task1_results_nms/{:s}.txt')\n",
        "    ###################################################################################################################\n",
        "    # change the directory to the path of val/labelTxt, if you want to do evaluation on the valset\n",
        "    # annopath = r'data/dota/test/OrientlabelTxt-utf-8/{:s}.txt'\n",
        "    # imagesetfile = r'data/dota/test/testset.txt'\n",
        "    annopath = r'/content/ReDet/data/dota/val/labelTxt/{:s}.txt'\n",
        "    imagesetfile = r'/content/ReDet/data/dota/val/testset.txt'\n",
        "\n",
        "    # For DOTA-v1.5\n",
        "    # classnames = ['plane', 'baseball-diamond', 'bridge', 'ground-track-field', 'small-vehicle', 'large-vehicle', 'ship', 'tennis-court',\n",
        "    #             'basketball-court', 'storage-tank',  'soccer-ball-field', 'roundabout', 'harbor', 'swimming-pool', 'helicopter', 'container-crane']\n",
        "    # For DOTA-v1.0\n",
        "    classnames = ['plane', 'baseball-diamond', 'bridge', 'ground-track-field', 'small-vehicle', 'large-vehicle', 'ship', 'tennis-court',\n",
        "                  'basketball-court', 'storage-tank',  'soccer-ball-field', 'roundabout', 'harbor', 'swimming-pool', 'helicopter']\n",
        "    classaps = []\n",
        "    map = 0\n",
        "    for classname in classnames:\n",
        "        print('classname:', classname)\n",
        "        rec, prec, ap = voc_eval(detpath,\n",
        "                                 annopath,\n",
        "                                 imagesetfile,\n",
        "                                 classname,\n",
        "                                 ovthresh=0.5,\n",
        "                                 use_07_metric=True)\n",
        "        map = map + ap\n",
        "        #print('rec: ', rec, 'prec: ', prec, 'ap: ', ap)\n",
        "        print('ap: ', ap)\n",
        "        classaps.append(ap)\n",
        "\n",
        "        # # umcomment to show p-r curve of each category\n",
        "        # plt.figure(figsize=(8,4))\n",
        "        # plt.xlabel('Recall')\n",
        "        # plt.ylabel('Precision')\n",
        "        # plt.xticks(fontsize=11)\n",
        "        # plt.yticks(fontsize=11)\n",
        "        # plt.xlim(0, 1)\n",
        "        # plt.ylim(0, 1)\n",
        "        # ax = plt.gca()\n",
        "        # ax.spines['top'].set_color('none')\n",
        "        # ax.spines['right'].set_color('none')\n",
        "        # plt.plot(rec, prec)\n",
        "        # # plt.show()\n",
        "        # plt.savefig('pr_curve/{}.png'.format(classname))\n",
        "    map = map/len(classnames)\n",
        "    print('map:', map)\n",
        "    classaps = 100*np.array(classaps)\n",
        "    print('classaps: ', classaps)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAPhxdS5xQqB"
      },
      "source": [
        "!python /content/ReDet/DOTA_devkit/dota_evaluation_task1.py --work_dir /content/ReDet/work_dirs/ReDet_re50_refpn_1x_dota1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pVyc-0HwQQz"
      },
      "source": [
        "!python /content/ReDet/DOTA_devkit/dota_evaluation_task1.py --work_dir /content/ReDet/work_dirs/faster_rcnn_RoITrans_r50_fpn_1x_dota"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBWoyMp0rQXK"
      },
      "source": [
        "!python /content/ReDet/DOTA_devkit/dota_evaluation_task1.py --work_dir /content/ReDet/work_dirs/faster_rcnn_obb_r50_fpn_1x_dota"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxWx1_0TyElt"
      },
      "source": [
        "# لیست خروجی ولیدیشن‌ها"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcvEDMAAzDPB"
      },
      "source": [
        "**ReDet**\n",
        "\n",
        "map: 0.8514600172670281\n",
        "\n",
        "classaps:  [90.74063962 88.35952404 70.27778167 83.69586216 71.37892832 88.03846396\n",
        " 88.83972303 90.90909091 89.87234694 90.00746689 90.00924415 82.27596327\n",
        " 88.32895278 80.09628041 84.35975774]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpefhCoCyr-4"
      },
      "source": [
        "**faster_rcnn_RoITrans_r50_fpn_1x_dota**\n",
        "\n",
        "map: 0.8416679746473459\n",
        "\n",
        "classaps:  [90.14526646 87.5615606  73.58691439 80.72462287 74.76489526 88.86002316\n",
        " 88.68232501 90.59249634 87.15753582 90.14873059 75.92481942 85.70194711\n",
        " 87.96535504 81.13566148 79.54980843]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68rAtdGCyQAo"
      },
      "source": [
        "**faster_rcnn_obb_r50_fpn_1x_dota**\n",
        "\n",
        "map: 0.7869873566873331\n",
        "\n",
        "classaps:  [90.22626651 83.21467398 60.88286463 66.33192138 70.29939163 84.09063058\n",
        " 88.17042018 90.89576113 80.49975872 89.18961722 78.22831552 79.33052598\n",
        " 75.461711   71.27527659 72.38389998]"
      ]
    }
  ]
}